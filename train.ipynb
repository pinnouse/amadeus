{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('pytorch_env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "83b3b3995af6a949f2c348b2e9a5049beb91e2fc19a5e2ef4810ff03c78e07f3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os, sys\n",
    "import subprocess\n",
    "import re\n",
    "from argparse import ArgumentParser, ArgumentTypeError\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('-o', '--output', dest='output', default='', help='Location of output(s)')\n",
    "parser.add_argument('-d', '--debug', type=str2bool, dest='debug', default=True, help='Debug logging specific files and extra verbosity')\n",
    "parser.add_argument('-c', '--use_cuda', type=str2bool, dest='use_cuda', default=True, help='Use cuda if cuda supported')\n",
    "parser.add_argument('-a', '--artifacts', dest='artifacts', default='', help='Directory to save artifacts such as checkpoints')\n",
    "parser.add_argument('-e', '--epochs', type=int, dest='train_epochs', default=10, help='Number of epochs to train on')\n",
    "parser.add_argument('-p', '--print_every', type=int, dest='print_every', default=100, help='After how many iterations to print a status')\n",
    "parser.add_argument('-v', '--validate_every', type=int, dest='validate_every', default=10, help='After how many epochs to validate loss on test set')\n",
    "parser.add_argument('--validate_amount', type=int, dest='validate_amount', default=4, help='How many entries of the test set to validate on, 0 for all (default 4)')\n",
    "parser.add_argument('-s', '--save_every', type=int, dest='save_every', default=0, help='After how many epochs before saving a checkpoint (0 to turn off)')\n",
    "parser.add_argument('-t', '--test_split', type=float, dest='test_split', default=0.3, help='How much of the dataset to reserve for test/validate (between 0 and 1 exclusive)')\n",
    "parser.add_argument('-b', '--batch_size', type=int, dest='batch_size', default=1, help='Batch size to train on')\n",
    "\n",
    "parser.add_argument('--input_length', type=int, dest='input_length', default=0, help='Maximum input sequence length')\n",
    "parser.add_argument('--output_length', type=int, dest='output_length', default=0, help='Maximum output sequence length')\n",
    "parser.add_argument('--conversation_depth', type=int, dest=\"conversation_depth\", default=4, help='Depth of conversations, the minimum should be 2.')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "use_cuda = args.use_cuda and torch.has_cuda\n",
    "\n",
    "device = 'cuda' if use_cuda else 'cpu'\n",
    "\n",
    "model_dir = args.output\n",
    "artifacts_dir = args.artifacts\n",
    "\n",
    "input_length = args.input_length\n",
    "output_length = args.output_length\n",
    "\n",
    "train_epochs = max(args.train_epochs, 1)\n",
    "print_every = max(args.print_every, 1)\n",
    "validate_every = max(args.validate_every, 0)\n",
    "save_every = max(args.save_every, 0)\n",
    "batch_size = max(args.batch_size, 1)\n",
    "test_split = args.test_split\n",
    "if test_split <= 0 or test_split >= 1:\n",
    "    test_split = 0.3\n",
    "validate_amount = max(args.validate_amount, 0)\n",
    "\n",
    "debug_mode = args.debug\n",
    "\n",
    "conversation_depth = max(args.conversation_depth, 2)"
   ]
  },
  {
   "source": [
    "# Prepare the Data\n",
    "\n",
    "Create vocabulary and load the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vocab import Vocab\n",
    "voc = Vocab(input_length, conversation_depth=conversation_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOLDERS = [\n",
    "#     'ditfxx_subs', 'steins_gate_subs', 'guilty_crown_subs',\n",
    "#     'ngnl_subs', 'rezero_subs', 'promised_neverland_subs', 'your_lie_subs',\n",
    "#     'shield_hero_subs', 'fate_ubw_subs'\n",
    "#     ]\n",
    "\n",
    "multiplier = [60, 60 * 60, 24 * 60 * 60]\n",
    "def get_time(timestr: str) -> int:\n",
    "    time = timestr.split(':')\n",
    "    final_time = 0\n",
    "    ms = float(time[-1]) * 1000\n",
    "    final_time += int(ms)\n",
    "    for i in range(len(time)-2):\n",
    "        t = time[-2-i]\n",
    "        final_time += multiplier[i] * int(t)\n",
    "    return final_time\n",
    "\n",
    "normalize_pattern = re.compile(r'(\\{[\\\\\\*][\\w\\(\\)\\\\\\,\\*]*|\\})', re.M)\n",
    "sub_space = re.compile(r'(\\{|\\\\[nN])', re.M)\n",
    "insert_space = re.compile(r'([\\w\\\"])([\\.\\!\\,\\?\\W])')\n",
    "def normalize_text(text: str) -> str:\n",
    "    text = normalize_pattern.sub('', text)\n",
    "    text = sub_space.sub(' ', text)\n",
    "    text = re.sub(r'([\\'\\\"])', r' \\1 ', text)\n",
    "    text = re.sub(r'([\\.\\!\\?\\W])(\\w)', r'\\1 \\2', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return insert_space.sub(r'\\1 \\2', text)\n",
    "\n",
    "number_match = re.compile(r'\\d+')\n",
    "def match_num(text: str) -> int:\n",
    "    x = number_match.findall(text)\n",
    "    return int(''.join(x) if len(x) > 0 else 0)\n",
    "\n",
    "for folder in os.listdir('data'):\n",
    "    if not os.path.isdir(os.path.join('data', folder)):\n",
    "        continue\n",
    "    dir = os.listdir(os.path.join('data', folder))\n",
    "    dir.sort(key=match_num)\n",
    "    print(f'Parsing folder: {folder}')\n",
    "    for f in dir:\n",
    "        filepath = os.path.join(os.getcwd(), 'data', folder, f)\n",
    "        if not os.path.isfile(filepath): continue\n",
    "        if debug_mode:\n",
    "            print(f'  Opening file: {f}')\n",
    "        with open(filepath, 'r', encoding='utf-8', errors='ignore') as sub_file:\n",
    "            is_event = False\n",
    "            line = True\n",
    "            while not is_event and line:\n",
    "                line = sub_file.readline()\n",
    "                if not line: break\n",
    "                if line.rstrip() == \"[Events]\":\n",
    "                    is_event = True\n",
    "            current_format = False\n",
    "            current_conversation = []\n",
    "            \n",
    "            voc.switch_context(f)\n",
    "            line = True\n",
    "            # for line in sub_file.readlines():\n",
    "            while line:\n",
    "                try:\n",
    "                    line = sub_file.readline()\n",
    "                except UnicodeDecodeError:\n",
    "                    print('    Error decoding a line, skipped.')\n",
    "                if line.startswith('Format:'):\n",
    "                    line = line[len('Format:'):].strip().split(',')\n",
    "                    for i in range(len(line)):\n",
    "                        line[i] = line[i].strip()\n",
    "                    current_format = line\n",
    "                    continue\n",
    "                if current_format == False or not line.startswith('Dialogue:'): continue\n",
    "                line = line[len('Dialogue:'):].strip().split(',')\n",
    "                line[len(current_format)-1] = ','.join(line[len(current_format)-1:])\n",
    "                dialogue = dict(zip(current_format, line))\n",
    "                if not dialogue['Style'].lower() in ['main', 'default', 'italics', 'flashback', 'ngnl-main']: continue\n",
    "                # Extract variables\n",
    "                speaker = ''\n",
    "                for k in ['Actor', 'Name']:\n",
    "                    if k in dialogue:\n",
    "                        speaker = dialogue[k]\n",
    "                        break\n",
    "                text = normalize_text(dialogue['Text'])\n",
    "                time = get_time(dialogue['Start'])\n",
    "                style = dialogue['Style']\n",
    "\n",
    "                if len(text.strip()) == 0: continue\n",
    "\n",
    "                voc.add_conversation({\n",
    "                    'speaker': speaker,\n",
    "                    'line': text,\n",
    "                    'when': time,\n",
    "                    'style': style\n",
    "                })\n",
    "                voc.add_sentence(text)\n",
    "\n",
    "convos = 0\n",
    "for k, c in voc.conversations.items():\n",
    "    convos += len(c)\n",
    "\n",
    "if input_length == 0:\n",
    "    input_length = 2**math.ceil(math.log2(voc.longest_tokenized * (conversation_depth - 1)))\n",
    "if output_length == 0:\n",
    "    output_length = 2**math.ceil(math.log2(voc.longest_tokenized))\n",
    "\n",
    "logger.info(f'Data loaded! Num conversations: {convos}, num words: {len(voc.words)}, longest convo: {voc.longest_tokenized}\\n\\n')"
   ]
  },
  {
   "source": [
    "# Create the Model\n",
    "\n",
    "Using preset hyperparameters from Amadeus"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amadeus_model import Amadeus\n",
    "\n",
    "model = Amadeus(num_tokens=voc.tokenizer.get_vocab_size(), \\\n",
    "    enc_seq_len=input_length, dec_seq_len=output_length)\n",
    "\n",
    "print(f'input size: {input_length} output size: {output_length}')"
   ]
  },
  {
   "source": [
    "# Train the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seq = torch.randint(0, voc.tokenizer.get_vocab_size(), (1, model.in_seq_len))\n",
    "out_seq = torch.randint(0, voc.tokenizer.get_vocab_size(), (1, model.out_seq_len))\n",
    "mask = torch.ones(1, model.in_seq_len).bool()\n",
    "\n",
    "try:\n",
    "    from torchviz import make_dot\n",
    "    y = model(in_seq, out_seq, mask=mask)\n",
    "    display(make_dot(y.mean(), params=dict(model.named_parameters())))\n",
    "except Exception:\n",
    "    print('Torch graph was not created, continuing.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=[in_seq.size(), out_seq.size()], dtypes=[torch.long, torch.long])\n",
    "\n",
    "in_seq = None\n",
    "out_seq = None\n",
    "mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "source": [
    "## Split train/test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from vocab import ConversationIter\n",
    "\n",
    "train_set, test_set = train_test_split(voc.get_conversations(), test_size=test_split)\n",
    "\n",
    "train_set = ConversationIter(train_set, in_seq_len=model.in_seq_len, \\\n",
    "    out_seq_len=model.out_seq_len, batch_size=batch_size)\n",
    "test_set = ConversationIter(test_set, in_seq_len=model.in_seq_len, \\\n",
    "    out_seq_len=model.out_seq_len, batch_size=batch_size)"
   ]
  },
  {
   "source": [
    "## Train the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adafactor import Adafactor\n",
    "\n",
    "has_gradient = False\n",
    "try:\n",
    "    from gradient_statsd import Client\n",
    "    has_gradient = True\n",
    "    client = Client()\n",
    "except ImportError:\n",
    "    print('gradient_statsd package is not installed, not using gradient metrics.')\n",
    "\n",
    "optimizer = Adafactor(model.parameters())\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "def format_time(dt: datetime) -> str:\n",
    "    return format(dt, '%Y-%m-%d-%H.%M.%S')\n",
    "\n",
    "gs_folder = f'amadeus-model-{format_time(start_time)}'\n",
    "\n",
    "def train(conv_iter: ConversationIter):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    counter = 0\n",
    "    accrued_loss = 0\n",
    "    start = datetime.now()\n",
    "    for i, (inputs, targets) in enumerate(conv_iter):\n",
    "        mask = torch.tensor([inp.attention_mask for inp in inputs], device=device, dtype=torch.bool)\n",
    "\n",
    "        inputs = torch.tensor([inp.ids for inp in inputs], device=device)\n",
    "        targets = torch.tensor([tar.ids for tar in targets], device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            loss = model(inputs, targets, mask=mask)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        accrued_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "        counter += 1\n",
    "        \n",
    "        if (i + 1) % print_every == 0:\n",
    "            print(f'  Iter {i+1} (Took {(datetime.now() - start).total_seconds():.3f}s): AverageLoss: {accrued_loss/print_every:.4f}')\n",
    "            total_loss += accrued_loss\n",
    "            accrued_loss = 0\n",
    "            start = datetime.now()\n",
    "    return total_loss / max(counter, 1)\n",
    "\n",
    "def validate(conv_iter: ConversationIter):\n",
    "    model.eval(False)\n",
    "    with torch.no_grad():\n",
    "        inp, tar = conv_iter.random_sample(amount=validate_amount)\n",
    "        mask = torch.tensor([i.attention_mask for i in inp], device=device, dtype=torch.bool)\n",
    "        inputs = torch.tensor([i.ids for i in inp], device=device)\n",
    "        targets = torch.tensor([t.ids for t in tar], device=device)\n",
    "        \n",
    "        loss = model(inputs, targets, mask=mask, return_loss=True)\n",
    "        print(f'Validation loss: {loss.item()}')\n",
    "        logger.info(f'Validation loss: {loss.item()}')\n",
    "    return loss.item()\n",
    "\n",
    "def save_checkpoint(epoch: int):\n",
    "    tmp_model_dir = artifacts_dir\n",
    "    if os.getenv('GCLOUD_ENABLE') and model_dir.startswith('gs://'):\n",
    "            tmp_model_dir = '/tmp'\n",
    "    checkpoint_path = os.path.join(tmp_model_dir, 'checkpoints')\n",
    "    checkpoint_name = f'amadeus-performer-{format_time(start_time)}-e{epoch}.chkpt'\n",
    "    checkpoint_file = os.path.join(checkpoint_path, checkpoint_name)\n",
    "    Path(checkpoint_path).mkdir(parents=True, exist_ok=True)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, checkpoint_file)\n",
    "\n",
    "    if os.getenv('GCLOUD_ENABLE') and artifacts_dir.startswith('gs://'):\n",
    "        subprocess.check_call([\n",
    "            'gsutil',\n",
    "            '-o', 'GSUtil:parallel_composite_upload_threshold=600M',\n",
    "            'cp', checkpoint_file,\n",
    "            os.path.join(artifacts_dir, gs_folder, checkpoint_name)\n",
    "        ])\n",
    "    print(f'Saved checkpoint: {checkpoint_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\n\\nStarting train on device: {device}')\n",
    "print(f'Training on {train_epochs} epochs with batch size of {batch_size}')\n",
    "print(f'Validating every {validate_every} and saving every {save_every}\\n')\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    prompt = f'Training epoch #{epoch+1} of {train_epochs}:'\n",
    "    print(f'{prompt}\\n{\"=\" * (len(prompt) + 8)}')\n",
    "    logger.info(prompt)\n",
    "\n",
    "    total = datetime.now()\n",
    "\n",
    "    total_loss = train(train_set)\n",
    "\n",
    "    if has_gradient:\n",
    "        client.increment('EPOCHS', 1)\n",
    "        client.gauge('LOSS_PER_EPOCH', total_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1} took {(datetime.now()-total).total_seconds():.3f}s (with loss {total_loss})')\n",
    "\n",
    "    if validate_every > 0 and (epoch + 1) % validate_every == 0:\n",
    "        validate_loss = validate(test_set)\n",
    "        if has_gradient:\n",
    "            client.gauge('VALIDATE_LOSS', validate_loss)\n",
    "\n",
    "    if save_every > 0 and (epoch + 1) % save_every == 0:\n",
    "        save_checkpoint(epoch + 1)\n",
    "\n",
    "    print('\\n\\n')\n",
    "\n",
    "tmp_model_dir = model_dir\n",
    "if os.getenv('GCLOUD_ENABLE') and model_dir.startswith('gs://'):\n",
    "        tmp_model_dir = '/tmp'\n",
    "model_path = os.path.join(tmp_model_dir, 'models')\n",
    "model_name = f'amadeus-performer-{format_time(start_time)}.pt'\n",
    "model_file = os.path.join(model_path, model_name)\n",
    "Path(model_path).mkdir(parents=True, exist_ok=True)\n",
    "torch.save(model.state_dict(), model_file)\n",
    "\n",
    "if os.getenv('GCLOUD_ENABLE') and model_dir.startswith('gs://'):\n",
    "    subprocess.check_call([\n",
    "        'gsutil',\n",
    "        '-o', 'GSUtil:parallel_composite_upload_threshold=600M',\n",
    "        'cp', model_file,\n",
    "        os.path.join(model_dir, gsfolder, model_name)\n",
    "    ])\n",
    "\n",
    "print('Finished training and saved model in models directory.')\n",
    "print(f'Saved file as: {model_name}')"
   ]
  }
 ]
}