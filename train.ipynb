{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "83b3b3995af6a949f2c348b2e9a5049beb91e2fc19a5e2ef4810ff03c78e07f3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os, sys\n",
    "import subprocess\n",
    "import re\n",
    "from argparse import ArgumentParser, ArgumentTypeError\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('-o', '--output', dest='output', default='', help='Location of output(s)')\n",
    "parser.add_argument('-d', '--debug', type=str2bool, dest='debug', default=True, help='Debug logging specific files and extra verbosity')\n",
    "parser.add_argument('-c', '--use_cuda', type=str2bool, dest='use_cuda', default=True, help='Use cuda if cuda supported')\n",
    "parser.add_argument('-a', '--artifacts', dest='artifacts', default='', help='Directory to save artifacts such as checkpoints')\n",
    "parser.add_argument('-e', '--epochs', type=int, dest='train_epochs', default=10, help='Number of epochs to train on')\n",
    "parser.add_argument('-p', '--print_every', type=int, dest='print_every', default=100, help='After how many iterations to print a status')\n",
    "parser.add_argument('-v', '--validate_every', type=int, dest='validate_every', default=10, help='After how many epochs to validate loss on test set')\n",
    "parser.add_argument('-s', '--save_every', type=int, dest='save_every', default=0, help='After how many epochs before saving a checkpoint (0 to turn off)')\n",
    "parser.add_argument('-b', '--batch_size', type=int, dest='batch_size', default=1, help='Batch size to train on')\n",
    "\n",
    "parser.add_argument('--input_length', type=int, dest='input_length', default=0, help='Maximum input sequence length')\n",
    "parser.add_argument('--output_length', type=int, dest='output_length', default=0, help='Maximum output sequence length')\n",
    "parser.add_argument('--conversation_depth', type=int, dest=\"conversation_depth\", default=4, help='Depth of conversations, the minimum should be 2.')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "use_cuda = args.use_cuda and torch.has_cuda\n",
    "\n",
    "device = 'cuda' if use_cuda else 'cpu'\n",
    "\n",
    "model_dir = args.output\n",
    "artifacts_dir = args.artifacts\n",
    "\n",
    "input_length = args.input_length\n",
    "output_length = args.output_length\n",
    "\n",
    "train_epochs = max(args.train_epochs, 1)\n",
    "print_every = max(args.print_every, 1)\n",
    "validate_every = max(args.validate_every, 0)\n",
    "save_every = max(args.save_every, 0)\n",
    "batch_size = max(args.batch_size, 1)\n",
    "\n",
    "debug_mode = args.debug\n",
    "\n",
    "conversation_depth = max(args.conversation_depth, 2)"
   ]
  },
  {
   "source": [
    "# Prepare the Data\n",
    "\n",
    "Create vocabulary and load the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vocab import Vocab\n",
    "voc = Vocab(input_length, conversation_depth=conversation_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parsing folder: aldnoah_zero_subs\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 01 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 02 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 03 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 04 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 05 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 06 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 07 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 08 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 09 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 10 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 11 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 12 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 13 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 14 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 15 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 16 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 17 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 18 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 19 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 20 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 21 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 22 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 23 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero - 24 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero S2 - 01 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero S2 - 02 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero S2 - 03 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero S2 - 04 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero S2 - 05 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero S2 - 06 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero S2 - 07 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero S2 - 08 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero S2 - 09 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero S2 - 10 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero S2 - 11 [720p].ass\n",
      "  Opening file: [HorribleSubs] Aldnoah Zero S2 - 12 [720p].ass\n",
      "Parsing folder: ditfxx_subs\n",
      "  Opening file: DitFXX(1).ass\n",
      "  Opening file: DitFXX(2).ass\n",
      "  Opening file: DitFXX(3).ass\n",
      "  Opening file: DitFXX(4).ass\n",
      "  Opening file: DitFXX(5).ass\n",
      "  Opening file: DitFXX(6).ass\n",
      "  Opening file: DitFXX(7).ass\n",
      "  Opening file: DitFXX(8).ass\n",
      "  Opening file: DitFXX(9).ass\n",
      "  Opening file: DitFXX(10).ass\n",
      "  Opening file: DitFXX(11).ass\n",
      "  Opening file: DitFXX(12).ass\n",
      "  Opening file: DitFXX(13).ass\n",
      "  Opening file: DitFXX(14).ass\n",
      "  Opening file: DitFXX(15).ass\n",
      "  Opening file: DitFXX(16).ass\n",
      "  Opening file: DitFXX(17).ass\n",
      "  Opening file: DitFXX(18).ass\n",
      "  Opening file: DitFXX(19).ass\n",
      "  Opening file: DitFXX(20).ass\n",
      "  Opening file: DitFXX(21).ass\n",
      "  Opening file: DitFXX(22).ass\n",
      "  Opening file: DitFXX(23).ass\n",
      "Parsing folder: fate_ubw_subs\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 00 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 02 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 03 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 04 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 05 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 06 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 07 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 08 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 09 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 10 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 11 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 01v2 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 12 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 13 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 14 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 15 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 16 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 17 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 18 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 19 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 20 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 21 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 22 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 23 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 24 [720p].ass\n",
      "  Opening file: [HorribleSubs] Fate Stay Night - Unlimited Blade Works - 25 [720p].ass\n",
      "Parsing folder: guilty_crown_subs\n",
      "  Opening file: [Commie] Guilty Crown - 05 [CEDCE7F8].ass\n",
      "  Opening file: [Commie] Guilty Crown - 18 [DD3DBE6E].ass\n",
      "  Opening file: [Commie] Guilty Crown - 03 [5EF0B8DB].ass\n",
      "  Opening file: [Commie] Guilty Crown - 07 [EF5FB5F1].ass\n",
      "  Opening file: [Commie] Guilty Crown - 01 [662BB1FD].ass\n",
      "  Opening file: [Commie] Guilty Crown - 04 [D917AC8F].ass\n",
      "  Opening file: [Commie] Guilty Crown - 08 [B171C9BB].ass\n",
      "  Opening file: [Commie] Guilty Crown - 13 [19A88BBA].ass\n",
      "  Opening file: [Commie] Guilty Crown - 16 [A9F55A7F].ass\n",
      "  Opening file: [Commie] Guilty Crown - 14 [18AB6B39].ass\n",
      "  Opening file: [Commie] Guilty Crown - 15 [E526E28E].ass\n",
      "  Opening file: [Commie] Guilty Crown - 20 [A98A9A05].ass\n",
      "  Opening file: [Commie] Guilty Crown - 02 [6D1930E8].ass\n",
      "  Opening file: [Commie] Guilty Crown - 06 [88FE8145].ass\n",
      "  Opening file: [Commie] Guilty Crown - 09 [52C0456D].ass\n",
      "  Opening file: [Commie] Guilty Crown - 11 [8C27E959].ass\n",
      "  Opening file: [Commie] Guilty Crown - 12 [243140FE].ass\n",
      "  Opening file: [Commie] Guilty Crown - 10 [6094511C].ass\n",
      "  Opening file: [Commie] Guilty Crown - 19 [77E06975].ass\n",
      "  Opening file: [Commie] Guilty Crown - 21v2 [012C508C].ass\n",
      "  Opening file: [Commie] Guilty Crown - 22 [1084F246].ass\n",
      "  Opening file: [Commie] Guilty Crown - 17 [78831216].ass\n",
      "Parsing folder: mahoutsukai_subs\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 01 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 02 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 03 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 04 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 05 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 06 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 07 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 08 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 09 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 10 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 11 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 12 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 13 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 14 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 15 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 16 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 17 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 18 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 19 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 20 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 21 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 22 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 23 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Mahoutsukai no Yome - 24 [720p]_track3_eng.ass\n",
      "Parsing folder: ngnl_subs\n",
      "  Opening file: [HorribleSubs] No Game No Life - 01 [720p].ass\n",
      "  Opening file: [HorribleSubs] No Game No Life - 02 [720p].ass\n",
      "  Opening file: [HorribleSubs] No Game No Life - 03 [720p].ass\n",
      "  Opening file: [HorribleSubs] No Game No Life - 04 [720p].ass\n",
      "  Opening file: [HorribleSubs] No Game No Life - 05 [720p].ass\n",
      "  Opening file: [HorribleSubs] No Game No Life - 06 [720p].ass\n",
      "  Opening file: [HorribleSubs] No Game No Life - 07 [720p].ass\n",
      "  Opening file: [HorribleSubs] No Game No Life - 08 [720p].ass\n",
      "  Opening file: [HorribleSubs] No Game No Life - 09 [720p].ass\n",
      "  Opening file: [HorribleSubs] No Game No Life - 10 [720p].ass\n",
      "  Opening file: [HorribleSubs] No Game No Life - 11 [720p].ass\n",
      "  Opening file: [HorribleSubs] No Game No Life - 12 [720p].ass\n",
      "Parsing folder: promised_neverland_subs\n",
      "  Opening file: [HorribleSubs] Yakusoku no Neverland - 01 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Yakusoku no Neverland - 02 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Yakusoku no Neverland - 03 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Yakusoku no Neverland - 04 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Yakusoku no Neverland - 05 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Yakusoku no Neverland - 06 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Yakusoku no Neverland - 07 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Yakusoku no Neverland - 08 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Yakusoku no Neverland - 09 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Yakusoku no Neverland - 10 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Yakusoku no Neverland - 11 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Yakusoku no Neverland - 12 [720p]_track3_eng.ass\n",
      "Parsing folder: rezero_subs\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 01A [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 01B [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 02 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 03 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 04 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 05 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 06 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 07 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 08 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 09 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 10 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 11 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 12 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 13 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 14 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 15 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 16 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 17 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 18 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 19 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 20 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 21 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 22 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 23 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 24 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Re Zero kara Hajimeru Isekai Seikatsu - 25 [720p]_track3_eng.ass\n",
      "Parsing folder: shield_hero_subs\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 01 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 02 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 03 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 04 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 05 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 06 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 07 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 08 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 09 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 10 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 11 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 12 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 13 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 14 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 15 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 16 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 17 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 18 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 19 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Tate no Yuusha no Nariagari - 20 [720p]_track3_eng.ass\n",
      "Parsing folder: steins_gate_subs\n",
      "  Opening file: Steins;Gate 01.ass\n",
      "  Opening file: Steins;Gate 02.ass\n",
      "  Opening file: Steins;Gate 03.ass\n",
      "  Opening file: Steins;Gate 04.ass\n",
      "  Opening file: Steins;Gate 05.ass\n",
      "  Opening file: Steins;Gate 06.ass\n",
      "  Opening file: Steins;Gate 07.ass\n",
      "  Opening file: Steins;Gate 08.ass\n",
      "  Opening file: Steins;Gate 09.ass\n",
      "  Opening file: Steins;Gate 10.ass\n",
      "  Opening file: Steins;Gate 11.ass\n",
      "  Opening file: Steins;Gate 12.ass\n",
      "  Opening file: Steins;Gate 13.ass\n",
      "  Opening file: Steins;Gate 14.ass\n",
      "  Opening file: Steins;Gate 15.ass\n",
      "  Opening file: Steins;Gate 16.ass\n",
      "  Opening file: Steins;Gate 17.ass\n",
      "  Opening file: Steins;Gate 18.ass\n",
      "  Opening file: Steins;Gate 19.ass\n",
      "  Opening file: Steins;Gate 20.ass\n",
      "  Opening file: Steins;Gate 21.ass\n",
      "  Opening file: Steins;Gate 22.ass\n",
      "  Opening file: Steins;Gate 23.ass\n",
      "  Opening file: Steins;Gate 24.ass\n",
      "  Opening file: Steins;Gate 25.ass\n",
      "Parsing folder: violet_evergarden_subs\n",
      "  Opening file: [HorribleSubs] Violet Evergarden - 01 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Violet Evergarden - 02 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Violet Evergarden - 03 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Violet Evergarden - 04 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Violet Evergarden - 05 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Violet Evergarden - 06 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Violet Evergarden - 07 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Violet Evergarden - 08 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Violet Evergarden - 09 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Violet Evergarden - 10 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Violet Evergarden - 11 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Violet Evergarden - 12 [720p]_track3_eng.ass\n",
      "  Opening file: [HorribleSubs] Violet Evergarden - 13 [720p]_track3_eng.ass\n",
      "Parsing folder: your_lie_subs\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 01 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 02 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 03 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 04 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 05 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 06 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 07 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 08 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 09 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 10 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 11 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 12 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 13 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 14 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 15 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 16 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 17 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 18 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 19 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 20 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 21 [720p].ass\n",
      "  Opening file: [HorribleSubs] Shigatsu wa Kimi no Uso - 22 [720p].ass\n",
      "  Opening file: [Ironanjuu] Shigatsu wa Kimi no Uso OVA [396p] [19A3C660].ass\n",
      "Done! Num conversations: 60966, num words: 14850, longest convo: 298\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FOLDERS = [\n",
    "#     'ditfxx_subs', 'steins_gate_subs', 'guilty_crown_subs',\n",
    "#     'ngnl_subs', 'rezero_subs', 'promised_neverland_subs', 'your_lie_subs',\n",
    "#     'shield_hero_subs', 'fate_ubw_subs'\n",
    "#     ]\n",
    "\n",
    "multiplier = [60, 60 * 60, 24 * 60 * 60]\n",
    "def get_time(timestr: str) -> int:\n",
    "    time = timestr.split(':')\n",
    "    final_time = 0\n",
    "    ms = float(time[-1]) * 1000\n",
    "    final_time += int(ms)\n",
    "    for i in range(len(time)-2):\n",
    "        t = time[-2-i]\n",
    "        final_time += multiplier[i] * int(t)\n",
    "    return final_time\n",
    "\n",
    "normalize_pattern = re.compile(r'(\\{[\\\\\\*][\\w\\(\\)\\\\\\,\\*]*|\\})', re.M)\n",
    "sub_space = re.compile(r'(\\{|\\\\[nN])', re.M)\n",
    "insert_space = re.compile(r'([\\w\\\"])([\\.\\!\\,\\?\\W])')\n",
    "def normalize_text(text: str) -> str:\n",
    "    text = normalize_pattern.sub('', text)\n",
    "    text = sub_space.sub(' ', text)\n",
    "    text = re.sub(r'([\\'\\\"])', r' \\1 ', text)\n",
    "    text = re.sub(r'([\\.\\!\\?\\W])(\\w)', r'\\1 \\2', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return insert_space.sub(r'\\1 \\2', text)\n",
    "\n",
    "number_match = re.compile(r'\\d+')\n",
    "def match_num(text: str) -> int:\n",
    "    x = number_match.findall(text)\n",
    "    return int(''.join(x) if len(x) > 0 else 0)\n",
    "\n",
    "for folder in os.listdir('data'):\n",
    "    if not os.path.isdir(os.path.join('data', folder)):\n",
    "        continue\n",
    "    dir = os.listdir(os.path.join('data', folder))\n",
    "    dir.sort(key=match_num)\n",
    "    print(f'Parsing folder: {folder}')\n",
    "    for f in dir:\n",
    "        filepath = os.path.join(os.getcwd(), 'data', folder, f)\n",
    "        if not os.path.isfile(filepath): continue\n",
    "        if debug_mode:\n",
    "            print(f'  Opening file: {f}')\n",
    "        with open(filepath, 'r', encoding='utf-8', errors='ignore') as sub_file:\n",
    "            is_event = False\n",
    "            line = True\n",
    "            while not is_event and line:\n",
    "                line = sub_file.readline()\n",
    "                if not line: break\n",
    "                if line.rstrip() == \"[Events]\":\n",
    "                    is_event = True\n",
    "            current_format = False\n",
    "            current_conversation = []\n",
    "            \n",
    "            voc.switch_context(f)\n",
    "            line = True\n",
    "            # for line in sub_file.readlines():\n",
    "            while line:\n",
    "                try:\n",
    "                    line = sub_file.readline()\n",
    "                except UnicodeDecodeError:\n",
    "                    print('    Error decoding a line, skipped.')\n",
    "                if line.startswith('Format:'):\n",
    "                    line = line[len('Format:'):].strip().split(',')\n",
    "                    for i in range(len(line)):\n",
    "                        line[i] = line[i].strip()\n",
    "                    current_format = line\n",
    "                    continue\n",
    "                if current_format == False or not line.startswith('Dialogue:'): continue\n",
    "                line = line[len('Dialogue:'):].strip().split(',')\n",
    "                line[len(current_format)-1] = ','.join(line[len(current_format)-1:])\n",
    "                dialogue = dict(zip(current_format, line))\n",
    "                if not dialogue['Style'].lower() in ['main', 'default', 'italics', 'flashback', 'ngnl-main']: continue\n",
    "                # Extract variables\n",
    "                speaker = ''\n",
    "                for k in ['Actor', 'Name']:\n",
    "                    if k in dialogue:\n",
    "                        speaker = dialogue[k]\n",
    "                        break\n",
    "                text = normalize_text(dialogue['Text'])\n",
    "                time = get_time(dialogue['Start'])\n",
    "                style = dialogue['Style']\n",
    "\n",
    "                if len(text.strip()) == 0: continue\n",
    "\n",
    "                voc.add_conversation({\n",
    "                    'speaker': speaker,\n",
    "                    'line': text,\n",
    "                    'when': time,\n",
    "                    'style': style\n",
    "                })\n",
    "                voc.add_sentence(text)\n",
    "\n",
    "convos = 0\n",
    "for k, c in voc.conversations.items():\n",
    "    convos += len(c)\n",
    "\n",
    "if input_length == 0:\n",
    "    input_length = 2**math.ceil(math.log2(voc.longest_tokenized * (conversation_depth - 1)))\n",
    "if output_length == 0:\n",
    "    output_length = 2**math.ceil(math.log2(voc.longest_tokenized))\n",
    "\n",
    "print(f'Done! Num conversations: {convos}, num words: {len(voc.words)}, longest convo: {voc.longest_tokenized}\\n\\n')"
   ]
  },
  {
   "source": [
    "# Create the Model\n",
    "\n",
    "Using preset hyperparameters from Amadeus"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n",
      "1024 512\n"
     ]
    }
   ],
   "source": [
    "from amadeus_model import Amadeus\n",
    "\n",
    "model = Amadeus(num_tokens=voc.tokenizer.get_vocab_size(), \\\n",
    "    enc_seq_len=input_length, dec_seq_len=output_length)\n",
    "\n",
    "print(f'input size: {input_length} output size: {output_length}')"
   ]
  },
  {
   "source": [
    "# Train the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<graphviz.dot.Digraph at 0x17372819a30>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n -->\r\n<!-- Title: %3 Pages: 1 -->\r\n<svg width=\"392pt\" height=\"796pt\"\r\n viewBox=\"0.00 0.00 391.50 796.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 792)\">\r\n<title>%3</title>\r\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-792 387.5,-792 387.5,4 -4,4\"/>\r\n<!-- 1595353963824 -->\r\n<g id=\"node1\" class=\"node\"><title>1595353963824</title>\r\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"127.5,-21 31.5,-21 31.5,-0 127.5,-0 127.5,-21\"/>\r\n<text text-anchor=\"middle\" x=\"79.5\" y=\"-7.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MeanBackward0</text>\r\n</g>\r\n<!-- 1595353963776 -->\r\n<g id=\"node2\" class=\"node\"><title>1595353963776</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"139,-78 20,-78 20,-57 139,-57 139,-78\"/>\r\n<text text-anchor=\"middle\" x=\"79.5\" y=\"-64.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">UnsafeViewBackward</text>\r\n</g>\r\n<!-- 1595353963776&#45;&gt;1595353963824 -->\r\n<g id=\"edge1\" class=\"edge\"><title>1595353963776&#45;&gt;1595353963824</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M79.5,-56.9197C79.5,-49.9083 79.5,-40.1442 79.5,-31.4652\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"83.0001,-31.3408 79.5,-21.3408 76.0001,-31.3409 83.0001,-31.3408\"/>\r\n</g>\r\n<!-- 1595354100448 -->\r\n<g id=\"node3\" class=\"node\"><title>1595354100448</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"121,-135 38,-135 38,-114 121,-114 121,-135\"/>\r\n<text text-anchor=\"middle\" x=\"79.5\" y=\"-121.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MmBackward</text>\r\n</g>\r\n<!-- 1595354100448&#45;&gt;1595353963776 -->\r\n<g id=\"edge2\" class=\"edge\"><title>1595354100448&#45;&gt;1595353963776</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M79.5,-113.92C79.5,-106.908 79.5,-97.1442 79.5,-88.4652\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"83.0001,-88.3408 79.5,-78.3408 76.0001,-88.3409 83.0001,-88.3408\"/>\r\n</g>\r\n<!-- 1595354100544 -->\r\n<g id=\"node4\" class=\"node\"><title>1595354100544</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"179.5,-192 91.5,-192 91.5,-171 179.5,-171 179.5,-192\"/>\r\n<text text-anchor=\"middle\" x=\"135.5\" y=\"-178.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">ViewBackward</text>\r\n</g>\r\n<!-- 1595354100544&#45;&gt;1595354100448 -->\r\n<g id=\"edge3\" class=\"edge\"><title>1595354100544&#45;&gt;1595354100448</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M125.746,-170.92C117.813,-163.129 106.421,-151.94 96.9288,-142.618\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"99.1068,-139.851 89.5198,-135.341 94.2018,-144.845 99.1068,-139.851\"/>\r\n</g>\r\n<!-- 1595354100736 -->\r\n<g id=\"node5\" class=\"node\"><title>1595354100736</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"249,-249 102,-249 102,-228 249,-228 249,-249\"/>\r\n<text text-anchor=\"middle\" x=\"175.5\" y=\"-235.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">NativeLayerNormBackward</text>\r\n</g>\r\n<!-- 1595354100736&#45;&gt;1595354100544 -->\r\n<g id=\"edge4\" class=\"edge\"><title>1595354100736&#45;&gt;1595354100544</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M168.533,-227.92C163.037,-220.363 155.215,-209.609 148.563,-200.462\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"151.369,-198.37 142.657,-192.341 145.708,-202.487 151.369,-198.37\"/>\r\n</g>\r\n<!-- 1595354100832 -->\r\n<g id=\"node6\" class=\"node\"><title>1595354100832</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"383.5,-312.5 293.5,-312.5 293.5,-291.5 383.5,-291.5 383.5,-312.5\"/>\r\n<text text-anchor=\"middle\" x=\"338.5\" y=\"-298.9\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">SumBackward1</text>\r\n</g>\r\n<!-- 1595354100832&#45;&gt;1595354100736 -->\r\n<g id=\"edge5\" class=\"edge\"><title>1595354100832&#45;&gt;1595354100736</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M313.031,-291.391C285.4,-280.965 241.113,-264.256 210.287,-252.625\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"211.382,-249.297 200.79,-249.042 208.911,-255.847 211.382,-249.297\"/>\r\n</g>\r\n<!-- 1595354101024 -->\r\n<g id=\"node7\" class=\"node\"><title>1595354101024</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"382.5,-376 292.5,-376 292.5,-355 382.5,-355 382.5,-376\"/>\r\n<text text-anchor=\"middle\" x=\"337.5\" y=\"-362.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">StackBackward</text>\r\n</g>\r\n<!-- 1595354101024&#45;&gt;1595354100832 -->\r\n<g id=\"edge6\" class=\"edge\"><title>1595354101024&#45;&gt;1595354100832</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M337.656,-354.891C337.795,-346.366 338.002,-333.639 338.176,-322.923\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"341.678,-322.8 338.342,-312.745 334.679,-322.687 341.678,-322.8\"/>\r\n</g>\r\n<!-- 1595354101120 -->\r\n<g id=\"node8\" class=\"node\"><title>1595354101120</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"379.5,-433 295.5,-433 295.5,-412 379.5,-412 379.5,-433\"/>\r\n<text text-anchor=\"middle\" x=\"337.5\" y=\"-419.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">SplitBackward</text>\r\n</g>\r\n<!-- 1595354101120&#45;&gt;1595354101024 -->\r\n<g id=\"edge7\" class=\"edge\"><title>1595354101120&#45;&gt;1595354101024</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M332.233,-411.92C330.855,-404.908 330.437,-395.144 330.98,-386.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"334.479,-386.684 332.183,-376.341 327.528,-385.858 334.479,-386.684\"/>\r\n</g>\r\n<!-- 1595354101120&#45;&gt;1595354101024 -->\r\n<g id=\"edge17\" class=\"edge\"><title>1595354101120&#45;&gt;1595354101024</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M342.767,-411.92C344.145,-404.908 344.563,-395.144 344.02,-386.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"347.472,-385.858 342.817,-376.341 340.521,-386.684 347.472,-385.858\"/>\r\n</g>\r\n<!-- 1595152217024 -->\r\n<g id=\"node9\" class=\"node\"><title>1595152217024</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"367.5,-490 211.5,-490 211.5,-469 367.5,-469 367.5,-490\"/>\r\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-476.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">_ReversibleFunctionBackward</text>\r\n</g>\r\n<!-- 1595152217024&#45;&gt;1595354101120 -->\r\n<g id=\"edge8\" class=\"edge\"><title>1595152217024&#45;&gt;1595354101120</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M297.861,-468.92C304.592,-461.207 314.23,-450.164 322.316,-440.898\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"324.973,-443.176 328.912,-433.341 319.699,-438.574 324.973,-443.176\"/>\r\n</g>\r\n<!-- 1595354101264 -->\r\n<g id=\"node10\" class=\"node\"><title>1595354101264</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"323.5,-547 243.5,-547 243.5,-526 323.5,-526 323.5,-547\"/>\r\n<text text-anchor=\"middle\" x=\"283.5\" y=\"-533.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">CatBackward</text>\r\n</g>\r\n<!-- 1595354101264&#45;&gt;1595152217024 -->\r\n<g id=\"edge9\" class=\"edge\"><title>1595354101264&#45;&gt;1595152217024</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M284.545,-525.92C285.31,-518.908 286.375,-509.144 287.322,-500.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"290.821,-500.661 288.426,-490.341 283.863,-499.902 290.821,-500.661\"/>\r\n</g>\r\n<!-- 1595354101456 -->\r\n<g id=\"node11\" class=\"node\"><title>1595354101456</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"327.5,-604 239.5,-604 239.5,-583 327.5,-583 327.5,-604\"/>\r\n<text text-anchor=\"middle\" x=\"283.5\" y=\"-590.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MulBackward0</text>\r\n</g>\r\n<!-- 1595354101456&#45;&gt;1595354101264 -->\r\n<g id=\"edge10\" class=\"edge\"><title>1595354101456&#45;&gt;1595354101264</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M278.233,-582.92C276.855,-575.908 276.437,-566.144 276.98,-557.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"280.479,-557.684 278.183,-547.341 273.528,-556.858 280.479,-557.684\"/>\r\n</g>\r\n<!-- 1595354101456&#45;&gt;1595354101264 -->\r\n<g id=\"edge16\" class=\"edge\"><title>1595354101456&#45;&gt;1595354101264</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M288.767,-582.92C290.145,-575.908 290.563,-566.144 290.02,-557.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"293.472,-556.858 288.817,-547.341 286.521,-557.684 293.472,-556.858\"/>\r\n</g>\r\n<!-- 1595354101552 -->\r\n<g id=\"node12\" class=\"node\"><title>1595354101552</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"304.5,-661 214.5,-661 214.5,-640 304.5,-640 304.5,-661\"/>\r\n<text text-anchor=\"middle\" x=\"259.5\" y=\"-647.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">AddBackward0</text>\r\n</g>\r\n<!-- 1595354101552&#45;&gt;1595354101456 -->\r\n<g id=\"edge11\" class=\"edge\"><title>1595354101552&#45;&gt;1595354101456</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M263.68,-639.92C266.842,-632.675 271.286,-622.49 275.165,-613.601\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"278.414,-614.906 279.206,-604.341 271.998,-612.106 278.414,-614.906\"/>\r\n</g>\r\n<!-- 1595354101648 -->\r\n<g id=\"node13\" class=\"node\"><title>1595354101648</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"183,-718 68,-718 68,-697 183,-697 183,-718\"/>\r\n<text text-anchor=\"middle\" x=\"125.5\" y=\"-704.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">EmbeddingBackward</text>\r\n</g>\r\n<!-- 1595354101648&#45;&gt;1595354101552 -->\r\n<g id=\"edge12\" class=\"edge\"><title>1595354101648&#45;&gt;1595354101552</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M148.841,-696.92C170.326,-688.101 202.419,-674.929 226.519,-665.037\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"228.055,-668.19 235.977,-661.155 225.397,-661.714 228.055,-668.19\"/>\r\n</g>\r\n<!-- 1595354101792 -->\r\n<g id=\"node14\" class=\"node\"><title>1595354101792</title>\r\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"142.5,-788 6.5,-788 6.5,-754 142.5,-754 142.5,-788\"/>\r\n<text text-anchor=\"middle\" x=\"74.5\" y=\"-774.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">dec.net.token_emb.weight</text>\r\n<text text-anchor=\"middle\" x=\"74.5\" y=\"-761.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (30522, 512)</text>\r\n</g>\r\n<!-- 1595354101792&#45;&gt;1595354101648 -->\r\n<g id=\"edge13\" class=\"edge\"><title>1595354101792&#45;&gt;1595354101648</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M87.8996,-753.842C95.0564,-745.211 103.869,-734.585 111.163,-725.789\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"113.898,-727.974 117.587,-718.042 108.51,-723.505 113.898,-727.974\"/>\r\n</g>\r\n<!-- 1595354100640 -->\r\n<g id=\"node19\" class=\"node\"><title>1595354100640</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"71,-661 0,-661 0,-640 71,-640 71,-661\"/>\r\n<text text-anchor=\"middle\" x=\"35.5\" y=\"-647.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">TBackward</text>\r\n</g>\r\n<!-- 1595354101792&#45;&gt;1595354100640 -->\r\n<g id=\"edge21\" class=\"edge\"><title>1595354101792&#45;&gt;1595354100640</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M69.0772,-753.523C61.9583,-731.892 49.4794,-693.976 41.9039,-670.958\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"45.1652,-669.671 38.7143,-661.267 38.516,-671.86 45.1652,-669.671\"/>\r\n</g>\r\n<!-- 1595354101696 -->\r\n<g id=\"node15\" class=\"node\"><title>1595354101696</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"317,-718 202,-718 202,-697 317,-697 317,-718\"/>\r\n<text text-anchor=\"middle\" x=\"259.5\" y=\"-704.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">EmbeddingBackward</text>\r\n</g>\r\n<!-- 1595354101696&#45;&gt;1595354101552 -->\r\n<g id=\"edge14\" class=\"edge\"><title>1595354101696&#45;&gt;1595354101552</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M259.5,-696.92C259.5,-689.908 259.5,-680.144 259.5,-671.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"263,-671.341 259.5,-661.341 256,-671.341 263,-671.341\"/>\r\n</g>\r\n<!-- 1595354101840 -->\r\n<g id=\"node16\" class=\"node\"><title>1595354101840</title>\r\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"323,-788 196,-788 196,-754 323,-754 323,-788\"/>\r\n<text text-anchor=\"middle\" x=\"259.5\" y=\"-774.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">dec.net.pos_emb.weight</text>\r\n<text text-anchor=\"middle\" x=\"259.5\" y=\"-761.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (512, 512)</text>\r\n</g>\r\n<!-- 1595354101840&#45;&gt;1595354101696 -->\r\n<g id=\"edge15\" class=\"edge\"><title>1595354101840&#45;&gt;1595354101696</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M259.5,-753.842C259.5,-746.012 259.5,-736.54 259.5,-728.282\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"263,-728.042 259.5,-718.042 256,-728.042 263,-728.042\"/>\r\n</g>\r\n<!-- 1595354100880 -->\r\n<g id=\"node17\" class=\"node\"><title>1595354100880</title>\r\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"159.5,-319 51.5,-319 51.5,-285 159.5,-285 159.5,-319\"/>\r\n<text text-anchor=\"middle\" x=\"105.5\" y=\"-305.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">dec.net.norm.weight</text>\r\n<text text-anchor=\"middle\" x=\"105.5\" y=\"-292.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (512)</text>\r\n</g>\r\n<!-- 1595354100880&#45;&gt;1595354100736 -->\r\n<g id=\"edge18\" class=\"edge\"><title>1595354100880&#45;&gt;1595354100736</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M123.892,-284.842C134.12,-275.855 146.811,-264.705 157.049,-255.711\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"159.437,-258.272 164.639,-249.042 154.817,-253.013 159.437,-258.272\"/>\r\n</g>\r\n<!-- 1595354100928 -->\r\n<g id=\"node18\" class=\"node\"><title>1595354100928</title>\r\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"275,-319 178,-319 178,-285 275,-285 275,-319\"/>\r\n<text text-anchor=\"middle\" x=\"226.5\" y=\"-305.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">dec.net.norm.bias</text>\r\n<text text-anchor=\"middle\" x=\"226.5\" y=\"-292.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (512)</text>\r\n</g>\r\n<!-- 1595354100928&#45;&gt;1595354100736 -->\r\n<g id=\"edge19\" class=\"edge\"><title>1595354100928&#45;&gt;1595354100736</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M213.1,-284.842C205.944,-276.211 197.131,-265.585 189.837,-256.789\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"192.49,-254.505 183.413,-249.042 187.102,-258.974 192.49,-254.505\"/>\r\n</g>\r\n<!-- 1595354100640&#45;&gt;1595354100448 -->\r\n<g id=\"edge20\" class=\"edge\"><title>1595354100640&#45;&gt;1595354100448</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M33.7807,-639.949C30.4626,-620.657 23.5,-575.634 23.5,-537.5 23.5,-537.5 23.5,-537.5 23.5,-237.5 23.5,-200.978 47.6172,-164.156 64.1978,-143.158\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"67.1115,-145.124 70.75,-135.174 61.7004,-140.683 67.1115,-145.124\"/>\r\n</g>\r\n</g>\r\n</svg>\r\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "in_seq = torch.randint(0, voc.tokenizer.get_vocab_size(), (1, model.in_seq_len))\n",
    "out_seq = torch.randint(0, voc.tokenizer.get_vocab_size(), (1, model.out_seq_len))\n",
    "mask = torch.ones(1, model.in_seq_len).bool()\n",
    "\n",
    "y = model(in_seq, out_seq, mask=mask)\n",
    "\n",
    "try:\n",
    "    from torchviz import make_dot\n",
    "    display(make_dot(y.mean(), params=dict(model.named_parameters())))\n",
    "except Exception:\n",
    "    print('Torch graph was not created, continuing.')\n",
    "\n",
    "in_seq = None\n",
    "out_seq = None\n",
    "mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "source": [
    "## Split train/test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from vocab import ConversationIter\n",
    "\n",
    "train_set, test_set = train_test_split(voc.get_conversations(), test_size=0.2)\n",
    "\n",
    "train_set = ConversationIter(train_set, in_seq_len=model.in_seq_len, \\\n",
    "    out_seq_len=model.out_seq_len, batch_size=batch_size)\n",
    "test_set = ConversationIter(test_set, in_seq_len=model.in_seq_len, \\\n",
    "    out_seq_len=model.out_seq_len, batch_size=batch_size)"
   ]
  },
  {
   "source": [
    "## Train the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gradient_statsd package is not installed, not using gradient metrics.\n"
     ]
    }
   ],
   "source": [
    "from adafactor import Adafactor\n",
    "\n",
    "has_gradient = False\n",
    "try:\n",
    "    from gradient_statsd import Client\n",
    "    has_gradient = True\n",
    "    client = Client()\n",
    "except ImportError:\n",
    "    print('gradient_statsd package is not installed, not using gradient metrics.')\n",
    "\n",
    "optimizer = Adafactor(model.parameters())\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "def format_time(dt: datetime) -> str:\n",
    "    return format(dt, '%Y-%m-%d-%H.%M.%S')\n",
    "\n",
    "def train(conv_iter: ConversationIter):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    counter = 0\n",
    "    accrued_loss = 0\n",
    "    start = datetime.now()\n",
    "    for i, (inputs, targets) in enumerate(conv_iter):\n",
    "        mask = torch.tensor([inp.attention_mask for inp in inputs]).bool()\n",
    "\n",
    "        inputs = torch.tensor([inp.ids for inp in inputs])\n",
    "        targets = torch.tensor([tar.ids for tar in targets])\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            mask = mask.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(inputs, targets, mask=mask, return_loss=True)\n",
    "        loss.mean().backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        accrued_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "        counter += 1\n",
    "        \n",
    "        if (i + 1) % print_every == 0:\n",
    "            print(f'  Iter {i+1} (Took {(datetime.now() - start).total_seconds():.3f}s): AverageLoss: {accrued_loss/print_every:.4f}')\n",
    "            total_loss += accrued_loss\n",
    "            accrued_loss = 0\n",
    "            start = datetime.now()\n",
    "    return total_loss / max(counter, 1)\n",
    "\n",
    "def validate(conv_iter: ConversationIter):\n",
    "    model.eval(False)\n",
    "    with torch.no_grad():\n",
    "        inp, tar = conv_iter.random_sample(pad_in=True)\n",
    "        mask = torch.tensor([i.attention_mask for i in inp]).bool()\n",
    "        inputs = torch.tensor([i.ids for i in inp])\n",
    "        targets = torch.tensor([t.ids for t in tar])\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            mask = mask.cuda()\n",
    "        \n",
    "        loss = model(inputs, targets, mask=mask, return_loss=True)\n",
    "        print(f'Validation loss: {loss.item()}')\n",
    "    return loss.item()\n",
    "\n",
    "def save_checkpoint(epoch: int):\n",
    "    tmp_model_dir = artifacts_dir\n",
    "    if os.getenv('GCLOUD_ENABLE') and model_dir.startswith('gs://'):\n",
    "            tmp_model_dir = '/tmp'\n",
    "    checkpoint_path = os.path.join(tmp_model_dir, 'checkpoints')\n",
    "    checkpoint_file = os.path.join(model_path, model_name)\n",
    "\n",
    "    checkpoint_name = f'amadeus-performer-{format_time(start_time)}-{epoch}.pt'\n",
    "    Path(checkpoint_path).mkdir(parents=True, exist_ok=True)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, checkpoint_file)\n",
    "\n",
    "    if os.getenv('GCLOUD_ENABLE') and artifacts_dir.startswith('gs://'):\n",
    "        subprocess.check_call([\n",
    "            'gsutil', 'cp', checkpoint_file,\n",
    "            os.path.join(artifacts_dir, checkpoint_name)\n",
    "        ])\n",
    "    print(f'Saved checkpoint: {checkpoint_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting train on device: cuda\n",
      "Training on 10 epochs with batch size of 1\n",
      "Validating every 10 and saving every 0\n",
      "\n",
      "Training epoch #1 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 41.938s): AverageLoss: 6.6036\n",
      "  Iter 200 (Took 39.397s): AverageLoss: 5.2143\n",
      "Epoch 1 took 97.461s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #2 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 39.073s): AverageLoss: 5.8062\n",
      "  Iter 200 (Took 38.968s): AverageLoss: 5.5060\n",
      "Epoch 2 took 113.707s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #3 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 37.644s): AverageLoss: 5.1180\n",
      "  Iter 200 (Took 37.348s): AverageLoss: 5.2133\n",
      "Epoch 3 took 103.029s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #4 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 36.577s): AverageLoss: 5.4950\n",
      "  Iter 200 (Took 34.654s): AverageLoss: 4.7368\n",
      "Epoch 4 took 72.592s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #5 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 35.162s): AverageLoss: 5.2096\n",
      "  Iter 200 (Took 35.301s): AverageLoss: 5.0634\n",
      "Epoch 5 took 96.184s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #6 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 37.986s): AverageLoss: 5.1109\n",
      "Epoch 6 took 46.132s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #7 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 34.101s): AverageLoss: 5.3970\n",
      "  Iter 200 (Took 36.536s): AverageLoss: 4.8153\n",
      "Epoch 7 took 90.121s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #8 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 37.429s): AverageLoss: 4.5795\n",
      "  Iter 200 (Took 37.575s): AverageLoss: 5.1644\n",
      "Epoch 8 took 104.127s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #9 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 34.742s): AverageLoss: 5.4517\n",
      "  Iter 200 (Took 33.441s): AverageLoss: 4.9064\n",
      "Epoch 9 took 69.180s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #10 of 10:\n",
      "=========================\n",
      "  Iter 100 (Took 34.778s): AverageLoss: 4.7373\n",
      "  Iter 200 (Took 36.179s): AverageLoss: 4.3231\n",
      "  Iter 300 (Took 34.218s): AverageLoss: 4.5910\n",
      "  Iter 400 (Took 33.813s): AverageLoss: 5.0217\n",
      "Epoch 10 took 153.308s\n",
      "Validation loss: 7.002444744110107\n",
      "\n",
      "\n",
      "\n",
      "Finished training and saved model in models directory.\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n\\nStarting train on device: {device}')\n",
    "print(f'Training on {train_epochs} epochs with batch size of {batch_size}')\n",
    "print(f'Validating every {validate_every} and saving every {save_every}\\n')\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    prompt = f'Training epoch #{epoch+1} of {train_epochs}:'\n",
    "    print(f'{prompt}\\n{\"=\" * len(prompt)}')\n",
    "\n",
    "    total = datetime.now()\n",
    "\n",
    "    total_loss = train(train_set)\n",
    "\n",
    "    if has_gradient:\n",
    "        client.increment('EPOCHS', 1)\n",
    "        client.gauge('LOSS_PER_EPOCH', total_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1} took {(datetime.now()-total).total_seconds():.3f}s')\n",
    "\n",
    "    if validate_every > 0 and (epoch + 1) % validate_every == 0:\n",
    "        validate_loss = validate(test_set)\n",
    "        if has_gradient:\n",
    "            client.gauge('VALIDATE_LOSS', validate_loss)\n",
    "\n",
    "    if save_every > 0 and (epoch + 1) % save_every == 0:\n",
    "        save_checkpoint(epoch + 1)\n",
    "\n",
    "    print('\\n\\n')\n",
    "\n",
    "tmp_model_dir = model_dir\n",
    "if os.getenv('GCLOUD_ENABLE') and model_dir.startswith('gs://'):\n",
    "        tmp_model_dir = '/tmp'\n",
    "model_path = os.path.join(tmp_model_dir, 'models')\n",
    "model_name = f'amadeus-performer-{format_time(start_time)}.pt'\n",
    "model_file = os.path.join(model_path, model_name)\n",
    "Path(model_path).mkdir(parents=True, exist_ok=True)\n",
    "torch.save(model.state_dict(), model_file)\n",
    "\n",
    "if os.getenv('GCLOUD_ENABLE') and model_dir.startswith('gs://'):\n",
    "    subprocess.check_call([\n",
    "        'gsutil', 'cp', model_file,\n",
    "        os.path.join(model_dir, model_name)\n",
    "    ])\n",
    "        \n",
    "print('Finished training and saved model in models directory.')"
   ]
  }
 ]
}