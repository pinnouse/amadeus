{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('pytorch_env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "83b3b3995af6a949f2c348b2e9a5049beb91e2fc19a5e2ef4810ff03c78e07f3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os, sys\n",
    "import re\n",
    "from argparse import ArgumentParser, ArgumentTypeError\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('-o', '--o', dest='output', default='', help='Location of output(s)')\n",
    "parser.add_argument('-g', '--use_cuda', type=str2bool, dest='use_cuda', default=True, help='Use cuda if cuda supported')\n",
    "parser.add_argument('-a', '--artifacts', dest='artifacts', default='', help='Directory to save artifacts such as checkpoints')\n",
    "parser.add_argument('-e', '--epochs', type=int, dest='train_epochs', default=10, help='Number of epochs to train on')\n",
    "parser.add_argument('-p', '--print_every', type=int, dest='print_every', default=100, help='After how many iterations to print a status')\n",
    "parser.add_argument('-t', '--validate_every', type=int, dest='validate_every', default=10, help='After how many epochs to validate loss on test set')\n",
    "parser.add_argument('-T', '--save_every', type=int, dest='save_every', default=0, help='After how many epochs before saving a checkpoint (0 to turn off)')\n",
    "parser.add_argument('-A', '--batch_size', type=int, dest='batch_size', default=1, help='Batch size to train on')\n",
    "\n",
    "parser.add_argument('--input_length', type=int, dest='input_length', default=0, help='Maximum input sequence length')\n",
    "parser.add_argument('--output_length', type=int, dest='output_length', default=0, help='Maximum output sequence length')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "use_cuda = args.use_cuda and torch.has_cuda\n",
    "\n",
    "device = 'cuda' if use_cuda else 'cpu'\n",
    "\n",
    "model_dir = args.output\n",
    "artifacts_dir = args.artifacts\n",
    "\n",
    "input_length = args.input_length\n",
    "output_length = args.output_length\n",
    "\n",
    "train_epochs = max(args.train_epochs, 1)\n",
    "print_every = max(args.print_every, 1)\n",
    "validate_every = max(args.validate_every, 0)\n",
    "save_every = max(args.save_every, 0)\n",
    "batch_size = max(args.batch_size, 1)"
   ]
  },
  {
   "source": [
    "# Prepare the Data\n",
    "\n",
    "Create vocabulary and load the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vocab import Vocab\n",
    "\n",
    "CONVERSATION_DEPTH = 4\n",
    "\n",
    "vocab = Vocab(input_length, conversation_depth=CONVERSATION_DEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parsing folder: ditfxx_subs\n",
      "  Opening file: DitFXX(1).ass\n",
      "  Opening file: DitFXX(2).ass\n",
      "  Opening file: DitFXX(3).ass\n",
      "  Opening file: DitFXX(4).ass\n",
      "  Opening file: DitFXX(5).ass\n",
      "  Opening file: DitFXX(6).ass\n",
      "  Opening file: DitFXX(7).ass\n",
      "  Opening file: DitFXX(8).ass\n",
      "  Opening file: DitFXX(9).ass\n",
      "  Opening file: DitFXX(10).ass\n",
      "  Opening file: DitFXX(11).ass\n",
      "  Opening file: DitFXX(12).ass\n",
      "  Opening file: DitFXX(13).ass\n",
      "  Opening file: DitFXX(14).ass\n",
      "  Opening file: DitFXX(15).ass\n",
      "  Opening file: DitFXX(16).ass\n",
      "  Opening file: DitFXX(17).ass\n",
      "  Opening file: DitFXX(18).ass\n",
      "  Opening file: DitFXX(19).ass\n",
      "  Opening file: DitFXX(20).ass\n",
      "  Opening file: DitFXX(21).ass\n",
      "  Opening file: DitFXX(22).ass\n",
      "  Opening file: DitFXX(23).ass\n",
      "Done! Num conversations: 4202, num words: 3664, longest convo: 281\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FOLDERS = [\n",
    "#     'ditfxx_subs', 'steins_gate_subs', 'guilty_crown_subs',\n",
    "#     'ngnl_subs', 'rezero_subs', 'promised_neverland_subs', 'your_lie_subs',\n",
    "#     'shield_hero_subs', 'fate_ubw_subs'\n",
    "#     ]\n",
    "\n",
    "multiplier = [60, 60 * 60, 24 * 60 * 60]\n",
    "def get_time(timestr: str) -> int:\n",
    "    time = timestr.split(':')\n",
    "    final_time = 0\n",
    "    ms = float(time[-1]) * 1000\n",
    "    final_time += int(ms)\n",
    "    for i in range(len(time)-2):\n",
    "        t = time[-2-i]\n",
    "        final_time += multiplier[i] * int(t)\n",
    "    return final_time\n",
    "\n",
    "normalize_pattern = re.compile(r'(\\{[\\\\\\*][\\w\\(\\)\\\\\\,\\*]*|\\})', re.M)\n",
    "sub_space = re.compile(r'(\\{|\\\\[nN])', re.M)\n",
    "insert_space = re.compile(r'([\\w\\\"])([\\.\\!\\,\\?\\W])')\n",
    "def normalize_text(text: str) -> str:\n",
    "    text = normalize_pattern.sub('', text)\n",
    "    text = sub_space.sub(' ', text)\n",
    "    text = re.sub(r'([\\'\\\"])', r' \\1 ', text)\n",
    "    text = re.sub(r'([\\.\\!\\?\\W])(\\w)', r'\\1 \\2', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return insert_space.sub(r'\\1 \\2', text)\n",
    "\n",
    "number_match = re.compile(r'\\d+')\n",
    "def match_num(text: str) -> int:\n",
    "    x = number_match.findall(text)\n",
    "    return int(''.join(x) if len(x) > 0 else 0)\n",
    "\n",
    "for folder in os.listdir('data'):\n",
    "    if not os.path.isdir(os.path.join('data', folder)):\n",
    "        continue\n",
    "    dir = os.listdir(os.path.join('data', folder))\n",
    "    dir.sort(key=match_num)\n",
    "    print(f'Parsing folder: {folder}')\n",
    "    for f in dir:\n",
    "        filepath = os.path.join(os.getcwd(), 'data', folder, f)\n",
    "        if not os.path.isfile(filepath): continue\n",
    "        print(f'  Opening file: {f}')\n",
    "        with open(filepath, 'r', encoding='utf-8', errors='ignore') as sub_file:\n",
    "            is_event = False\n",
    "            line = True\n",
    "            while not is_event and line:\n",
    "                line = sub_file.readline()\n",
    "                if not line: break\n",
    "                if line.rstrip() == \"[Events]\":\n",
    "                    is_event = True\n",
    "            current_format = False\n",
    "            current_conversation = []\n",
    "            \n",
    "            vocab.switch_context(f)\n",
    "            line = True\n",
    "            # for line in sub_file.readlines():\n",
    "            while line:\n",
    "                try:\n",
    "                    line = sub_file.readline()\n",
    "                except UnicodeDecodeError:\n",
    "                    print('    Error decoding a line, skipped.')\n",
    "                if line.startswith('Format:'):\n",
    "                    line = line[len('Format:'):].strip().split(', ')\n",
    "                    current_format = line\n",
    "                    continue\n",
    "                if current_format == False or not line.startswith('Dialogue:'): continue\n",
    "                line = line[len('Dialogue:'):].strip().split(',')\n",
    "                line[len(current_format)-1] = ','.join(line[len(current_format)-1:])\n",
    "                dialogue = dict(zip(current_format, line))\n",
    "                if not dialogue['Style'] in ['main', 'Default', 'italics', 'flashback', 'ngnl-main']: continue\n",
    "                # Extract variables\n",
    "                speaker = dialogue['Name']\n",
    "                text = normalize_text(dialogue['Text'])\n",
    "                time = get_time(dialogue['Start'])\n",
    "                style = dialogue['Style']\n",
    "\n",
    "                if len(text.strip()) == 0: continue\n",
    "\n",
    "                vocab.add_conversation({\n",
    "                    'speaker': speaker,\n",
    "                    'line': text,\n",
    "                    'when': time,\n",
    "                    'style': style\n",
    "                })\n",
    "                vocab.add_sentence(text)\n",
    "\n",
    "convos = 0\n",
    "for k, c in vocab.conversations.items():\n",
    "    convos += len(c)\n",
    "\n",
    "if input_length == 0:\n",
    "    input_length = 2**math.ceil(math.log2(vocab.longest_tokenized))\n",
    "if output_length == 0:\n",
    "    output_length = 2**math.ceil(math.log2(vocab.longest_tokenized * (CONVERSATION_DEPTH - 1)))\n",
    "\n",
    "print(f'Done! Num conversations: {convos}, num words: {len(vocab.words)}, longest convo: {vocab.longest_tokenized}\\n\\n')"
   ]
  },
  {
   "source": [
    "# Create the Model\n",
    "\n",
    "Using preset hyperparameters from Amadeus"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "unable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\nunable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\nunable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\nunable to import cuda code for auto-regressive Performer. will default to the memory inefficient non-cuda version\n512 1024\n"
     ]
    }
   ],
   "source": [
    "from amadeus_model import Amadeus\n",
    "\n",
    "model = Amadeus(num_tokens=vocab.tokenizer.get_vocab_size(), \\\n",
    "    enc_seq_len=input_length, dec_seq_len=output_length)\n",
    "\n",
    "print(input_length, output_length)"
   ]
  },
  {
   "source": [
    "# Train the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<graphviz.dot.Digraph at 0x1504fdc8130>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n -->\r\n<!-- Title: %3 Pages: 1 -->\r\n<svg width=\"392pt\" height=\"796pt\"\r\n viewBox=\"0.00 0.00 391.50 796.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 792)\">\r\n<title>%3</title>\r\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-792 387.5,-792 387.5,4 -4,4\"/>\r\n<!-- 1444448862464 -->\r\n<g id=\"node1\" class=\"node\"><title>1444448862464</title>\r\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"127.5,-21 31.5,-21 31.5,-0 127.5,-0 127.5,-21\"/>\r\n<text text-anchor=\"middle\" x=\"79.5\" y=\"-7.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MeanBackward0</text>\r\n</g>\r\n<!-- 1444448862608 -->\r\n<g id=\"node2\" class=\"node\"><title>1444448862608</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"139,-78 20,-78 20,-57 139,-57 139,-78\"/>\r\n<text text-anchor=\"middle\" x=\"79.5\" y=\"-64.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">UnsafeViewBackward</text>\r\n</g>\r\n<!-- 1444448862608&#45;&gt;1444448862464 -->\r\n<g id=\"edge1\" class=\"edge\"><title>1444448862608&#45;&gt;1444448862464</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M79.5,-56.9197C79.5,-49.9083 79.5,-40.1442 79.5,-31.4652\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"83.0001,-31.3408 79.5,-21.3408 76.0001,-31.3409 83.0001,-31.3408\"/>\r\n</g>\r\n<!-- 1444448995072 -->\r\n<g id=\"node3\" class=\"node\"><title>1444448995072</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"121,-135 38,-135 38,-114 121,-114 121,-135\"/>\r\n<text text-anchor=\"middle\" x=\"79.5\" y=\"-121.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MmBackward</text>\r\n</g>\r\n<!-- 1444448995072&#45;&gt;1444448862608 -->\r\n<g id=\"edge2\" class=\"edge\"><title>1444448995072&#45;&gt;1444448862608</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M79.5,-113.92C79.5,-106.908 79.5,-97.1442 79.5,-88.4652\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"83.0001,-88.3408 79.5,-78.3408 76.0001,-88.3409 83.0001,-88.3408\"/>\r\n</g>\r\n<!-- 1444448995168 -->\r\n<g id=\"node4\" class=\"node\"><title>1444448995168</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"179.5,-192 91.5,-192 91.5,-171 179.5,-171 179.5,-192\"/>\r\n<text text-anchor=\"middle\" x=\"135.5\" y=\"-178.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">ViewBackward</text>\r\n</g>\r\n<!-- 1444448995168&#45;&gt;1444448995072 -->\r\n<g id=\"edge3\" class=\"edge\"><title>1444448995168&#45;&gt;1444448995072</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M125.746,-170.92C117.813,-163.129 106.421,-151.94 96.9288,-142.618\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"99.1068,-139.851 89.5198,-135.341 94.2018,-144.845 99.1068,-139.851\"/>\r\n</g>\r\n<!-- 1444448995360 -->\r\n<g id=\"node5\" class=\"node\"><title>1444448995360</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"249,-249 102,-249 102,-228 249,-228 249,-249\"/>\r\n<text text-anchor=\"middle\" x=\"175.5\" y=\"-235.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">NativeLayerNormBackward</text>\r\n</g>\r\n<!-- 1444448995360&#45;&gt;1444448995168 -->\r\n<g id=\"edge4\" class=\"edge\"><title>1444448995360&#45;&gt;1444448995168</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M168.533,-227.92C163.037,-220.363 155.215,-209.609 148.563,-200.462\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"151.369,-198.37 142.657,-192.341 145.708,-202.487 151.369,-198.37\"/>\r\n</g>\r\n<!-- 1444448995456 -->\r\n<g id=\"node6\" class=\"node\"><title>1444448995456</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"383.5,-312.5 293.5,-312.5 293.5,-291.5 383.5,-291.5 383.5,-312.5\"/>\r\n<text text-anchor=\"middle\" x=\"338.5\" y=\"-298.9\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">SumBackward1</text>\r\n</g>\r\n<!-- 1444448995456&#45;&gt;1444448995360 -->\r\n<g id=\"edge5\" class=\"edge\"><title>1444448995456&#45;&gt;1444448995360</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M313.031,-291.391C285.4,-280.965 241.113,-264.256 210.287,-252.625\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"211.382,-249.297 200.79,-249.042 208.911,-255.847 211.382,-249.297\"/>\r\n</g>\r\n<!-- 1444448995648 -->\r\n<g id=\"node7\" class=\"node\"><title>1444448995648</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"382.5,-376 292.5,-376 292.5,-355 382.5,-355 382.5,-376\"/>\r\n<text text-anchor=\"middle\" x=\"337.5\" y=\"-362.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">StackBackward</text>\r\n</g>\r\n<!-- 1444448995648&#45;&gt;1444448995456 -->\r\n<g id=\"edge6\" class=\"edge\"><title>1444448995648&#45;&gt;1444448995456</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M337.656,-354.891C337.795,-346.366 338.002,-333.639 338.176,-322.923\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"341.678,-322.8 338.342,-312.745 334.679,-322.687 341.678,-322.8\"/>\r\n</g>\r\n<!-- 1444448995744 -->\r\n<g id=\"node8\" class=\"node\"><title>1444448995744</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"379.5,-433 295.5,-433 295.5,-412 379.5,-412 379.5,-433\"/>\r\n<text text-anchor=\"middle\" x=\"337.5\" y=\"-419.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">SplitBackward</text>\r\n</g>\r\n<!-- 1444448995744&#45;&gt;1444448995648 -->\r\n<g id=\"edge7\" class=\"edge\"><title>1444448995744&#45;&gt;1444448995648</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M332.233,-411.92C330.855,-404.908 330.437,-395.144 330.98,-386.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"334.479,-386.684 332.183,-376.341 327.528,-385.858 334.479,-386.684\"/>\r\n</g>\r\n<!-- 1444448995744&#45;&gt;1444448995648 -->\r\n<g id=\"edge17\" class=\"edge\"><title>1444448995744&#45;&gt;1444448995648</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M342.767,-411.92C344.145,-404.908 344.563,-395.144 344.02,-386.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"347.472,-385.858 342.817,-376.341 340.521,-386.684 347.472,-385.858\"/>\r\n</g>\r\n<!-- 1444311830080 -->\r\n<g id=\"node9\" class=\"node\"><title>1444311830080</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"367.5,-490 211.5,-490 211.5,-469 367.5,-469 367.5,-490\"/>\r\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-476.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">_ReversibleFunctionBackward</text>\r\n</g>\r\n<!-- 1444311830080&#45;&gt;1444448995744 -->\r\n<g id=\"edge8\" class=\"edge\"><title>1444311830080&#45;&gt;1444448995744</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M297.861,-468.92C304.592,-461.207 314.23,-450.164 322.316,-440.898\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"324.973,-443.176 328.912,-433.341 319.699,-438.574 324.973,-443.176\"/>\r\n</g>\r\n<!-- 1444448995888 -->\r\n<g id=\"node10\" class=\"node\"><title>1444448995888</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"323.5,-547 243.5,-547 243.5,-526 323.5,-526 323.5,-547\"/>\r\n<text text-anchor=\"middle\" x=\"283.5\" y=\"-533.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">CatBackward</text>\r\n</g>\r\n<!-- 1444448995888&#45;&gt;1444311830080 -->\r\n<g id=\"edge9\" class=\"edge\"><title>1444448995888&#45;&gt;1444311830080</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M284.545,-525.92C285.31,-518.908 286.375,-509.144 287.322,-500.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"290.821,-500.661 288.426,-490.341 283.863,-499.902 290.821,-500.661\"/>\r\n</g>\r\n<!-- 1444448996080 -->\r\n<g id=\"node11\" class=\"node\"><title>1444448996080</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"327.5,-604 239.5,-604 239.5,-583 327.5,-583 327.5,-604\"/>\r\n<text text-anchor=\"middle\" x=\"283.5\" y=\"-590.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MulBackward0</text>\r\n</g>\r\n<!-- 1444448996080&#45;&gt;1444448995888 -->\r\n<g id=\"edge10\" class=\"edge\"><title>1444448996080&#45;&gt;1444448995888</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M278.233,-582.92C276.855,-575.908 276.437,-566.144 276.98,-557.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"280.479,-557.684 278.183,-547.341 273.528,-556.858 280.479,-557.684\"/>\r\n</g>\r\n<!-- 1444448996080&#45;&gt;1444448995888 -->\r\n<g id=\"edge16\" class=\"edge\"><title>1444448996080&#45;&gt;1444448995888</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M288.767,-582.92C290.145,-575.908 290.563,-566.144 290.02,-557.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"293.472,-556.858 288.817,-547.341 286.521,-557.684 293.472,-556.858\"/>\r\n</g>\r\n<!-- 1444448996176 -->\r\n<g id=\"node12\" class=\"node\"><title>1444448996176</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"304.5,-661 214.5,-661 214.5,-640 304.5,-640 304.5,-661\"/>\r\n<text text-anchor=\"middle\" x=\"259.5\" y=\"-647.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">AddBackward0</text>\r\n</g>\r\n<!-- 1444448996176&#45;&gt;1444448996080 -->\r\n<g id=\"edge11\" class=\"edge\"><title>1444448996176&#45;&gt;1444448996080</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M263.68,-639.92C266.842,-632.675 271.286,-622.49 275.165,-613.601\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"278.414,-614.906 279.206,-604.341 271.998,-612.106 278.414,-614.906\"/>\r\n</g>\r\n<!-- 1444448996272 -->\r\n<g id=\"node13\" class=\"node\"><title>1444448996272</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"183,-718 68,-718 68,-697 183,-697 183,-718\"/>\r\n<text text-anchor=\"middle\" x=\"125.5\" y=\"-704.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">EmbeddingBackward</text>\r\n</g>\r\n<!-- 1444448996272&#45;&gt;1444448996176 -->\r\n<g id=\"edge12\" class=\"edge\"><title>1444448996272&#45;&gt;1444448996176</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M148.841,-696.92C170.326,-688.101 202.419,-674.929 226.519,-665.037\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"228.055,-668.19 235.977,-661.155 225.397,-661.714 228.055,-668.19\"/>\r\n</g>\r\n<!-- 1444448996416 -->\r\n<g id=\"node14\" class=\"node\"><title>1444448996416</title>\r\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"142.5,-788 6.5,-788 6.5,-754 142.5,-754 142.5,-788\"/>\r\n<text text-anchor=\"middle\" x=\"74.5\" y=\"-774.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">dec.net.token_emb.weight</text>\r\n<text text-anchor=\"middle\" x=\"74.5\" y=\"-761.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (30522, 512)</text>\r\n</g>\r\n<!-- 1444448996416&#45;&gt;1444448996272 -->\r\n<g id=\"edge13\" class=\"edge\"><title>1444448996416&#45;&gt;1444448996272</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M87.8996,-753.842C95.0564,-745.211 103.869,-734.585 111.163,-725.789\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"113.898,-727.974 117.587,-718.042 108.51,-723.505 113.898,-727.974\"/>\r\n</g>\r\n<!-- 1444448995264 -->\r\n<g id=\"node19\" class=\"node\"><title>1444448995264</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"71,-661 0,-661 0,-640 71,-640 71,-661\"/>\r\n<text text-anchor=\"middle\" x=\"35.5\" y=\"-647.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">TBackward</text>\r\n</g>\r\n<!-- 1444448996416&#45;&gt;1444448995264 -->\r\n<g id=\"edge21\" class=\"edge\"><title>1444448996416&#45;&gt;1444448995264</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M69.0772,-753.523C61.9583,-731.892 49.4794,-693.976 41.9039,-670.958\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"45.1652,-669.671 38.7143,-661.267 38.516,-671.86 45.1652,-669.671\"/>\r\n</g>\r\n<!-- 1444448996320 -->\r\n<g id=\"node15\" class=\"node\"><title>1444448996320</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"317,-718 202,-718 202,-697 317,-697 317,-718\"/>\r\n<text text-anchor=\"middle\" x=\"259.5\" y=\"-704.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">EmbeddingBackward</text>\r\n</g>\r\n<!-- 1444448996320&#45;&gt;1444448996176 -->\r\n<g id=\"edge14\" class=\"edge\"><title>1444448996320&#45;&gt;1444448996176</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M259.5,-696.92C259.5,-689.908 259.5,-680.144 259.5,-671.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"263,-671.341 259.5,-661.341 256,-671.341 263,-671.341\"/>\r\n</g>\r\n<!-- 1444448996464 -->\r\n<g id=\"node16\" class=\"node\"><title>1444448996464</title>\r\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"323,-788 196,-788 196,-754 323,-754 323,-788\"/>\r\n<text text-anchor=\"middle\" x=\"259.5\" y=\"-774.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">dec.net.pos_emb.weight</text>\r\n<text text-anchor=\"middle\" x=\"259.5\" y=\"-761.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (1024, 512)</text>\r\n</g>\r\n<!-- 1444448996464&#45;&gt;1444448996320 -->\r\n<g id=\"edge15\" class=\"edge\"><title>1444448996464&#45;&gt;1444448996320</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M259.5,-753.842C259.5,-746.012 259.5,-736.54 259.5,-728.282\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"263,-728.042 259.5,-718.042 256,-728.042 263,-728.042\"/>\r\n</g>\r\n<!-- 1444448995504 -->\r\n<g id=\"node17\" class=\"node\"><title>1444448995504</title>\r\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"159.5,-319 51.5,-319 51.5,-285 159.5,-285 159.5,-319\"/>\r\n<text text-anchor=\"middle\" x=\"105.5\" y=\"-305.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">dec.net.norm.weight</text>\r\n<text text-anchor=\"middle\" x=\"105.5\" y=\"-292.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (512)</text>\r\n</g>\r\n<!-- 1444448995504&#45;&gt;1444448995360 -->\r\n<g id=\"edge18\" class=\"edge\"><title>1444448995504&#45;&gt;1444448995360</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M123.892,-284.842C134.12,-275.855 146.811,-264.705 157.049,-255.711\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"159.437,-258.272 164.639,-249.042 154.817,-253.013 159.437,-258.272\"/>\r\n</g>\r\n<!-- 1444448995552 -->\r\n<g id=\"node18\" class=\"node\"><title>1444448995552</title>\r\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"275,-319 178,-319 178,-285 275,-285 275,-319\"/>\r\n<text text-anchor=\"middle\" x=\"226.5\" y=\"-305.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">dec.net.norm.bias</text>\r\n<text text-anchor=\"middle\" x=\"226.5\" y=\"-292.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (512)</text>\r\n</g>\r\n<!-- 1444448995552&#45;&gt;1444448995360 -->\r\n<g id=\"edge19\" class=\"edge\"><title>1444448995552&#45;&gt;1444448995360</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M213.1,-284.842C205.944,-276.211 197.131,-265.585 189.837,-256.789\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"192.49,-254.505 183.413,-249.042 187.102,-258.974 192.49,-254.505\"/>\r\n</g>\r\n<!-- 1444448995264&#45;&gt;1444448995072 -->\r\n<g id=\"edge20\" class=\"edge\"><title>1444448995264&#45;&gt;1444448995072</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M33.7807,-639.949C30.4626,-620.657 23.5,-575.634 23.5,-537.5 23.5,-537.5 23.5,-537.5 23.5,-237.5 23.5,-200.978 47.6172,-164.156 64.1978,-143.158\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"67.1115,-145.124 70.75,-135.174 61.7004,-140.683 67.1115,-145.124\"/>\r\n</g>\r\n</g>\r\n</svg>\r\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "in_seq = torch.randint(0, vocab.tokenizer.get_vocab_size(), (1, model.in_seq_len))\n",
    "out_seq = torch.randint(0, vocab.tokenizer.get_vocab_size(), (1, model.out_seq_len))\n",
    "mask = torch.ones(1, model.in_seq_len).bool()\n",
    "\n",
    "y = model(in_seq, out_seq, mask=mask)\n",
    "\n",
    "try:\n",
    "    from torchviz import make_dot\n",
    "    display(make_dot(y.mean(), params=dict(model.named_parameters())))\n",
    "except Exception:\n",
    "    print('Torch graph was not created, continuing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "source": [
    "## Split train/test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from vocab import ConversationIter\n",
    "\n",
    "conversations = list(vocab.conversations.values())\n",
    "conversations = list(filter(lambda c: len(c) > 0, conversations))\n",
    "\n",
    "train_set, test_set = train_test_split(conversations, test_size=0.2)\n",
    "\n",
    "train_set = ConversationIter(train_set, in_seq_len=model.in_seq_len, \\\n",
    "    out_seq_len=model.out_seq_len, tokenizer=vocab.tokenizer, batch_size=batch_size)\n",
    "test_set = ConversationIter(test_set, in_seq_len=model.in_seq_len, \\\n",
    "    out_seq_len=model.out_seq_len, tokenizer=vocab.tokenizer, batch_size=batch_size)"
   ]
  },
  {
   "source": [
    "## Train the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gradient_statsd package is not installed, not using gradient metrics.\n"
     ]
    }
   ],
   "source": [
    "from adafactor import Adafactor\n",
    "\n",
    "has_gradient = False\n",
    "try:\n",
    "    from gradient_statsd import Client\n",
    "    has_gradient = True\n",
    "    client = Client()\n",
    "except ImportError:\n",
    "    print('gradient_statsd package is not installed, not using gradient metrics.')\n",
    "\n",
    "optimizer = Adafactor(model.parameters())\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "def format_time(dt: datetime) -> str:\n",
    "    return format(dt, '%Y-%m-%d-%H.%M.%S')\n",
    "\n",
    "def train(conv_iter: ConversationIter):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    counter = 0\n",
    "    accrued_loss = 0\n",
    "    start = datetime.now()\n",
    "    for i, (inputs, targets) in enumerate(conv_iter):\n",
    "        mask = torch.tensor([inp.attention_mask for inp in inputs]).bool()\n",
    "\n",
    "        inputs = torch.tensor([inp.ids for inp in inputs])\n",
    "        targets = torch.tensor([tar.ids for tar in targets])\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            mask = mask.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(inputs, targets, mask=mask, return_loss=True)\n",
    "        loss.mean().backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        accrued_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "        counter += 1\n",
    "        \n",
    "        if (i + 1) % print_every == 0:\n",
    "            print(f'  Iter {i+1} (Took {(datetime.now() - start).total_seconds():.3f}s): AverageLoss: {accrued_loss/print_every:.4f}')\n",
    "            total_loss += accrued_loss\n",
    "            accrued_loss = 0\n",
    "            start = datetime.now()\n",
    "    return total_loss / max(counter, 1)\n",
    "\n",
    "def validate(conv_iter: ConversationIter):\n",
    "    model.eval(False)\n",
    "    with torch.no_grad():\n",
    "        inp, tar = conv_iter.random_sample(pad_in=True)\n",
    "        mask = torch.tensor([i.attention_mask for i in inp]).bool()\n",
    "        inputs = torch.tensor([i.ids for i in inp])\n",
    "        targets = torch.tensor([t.ids for t in tar])\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            mask = mask.cuda()\n",
    "        \n",
    "        loss = model(inputs, targets, mask=mask, return_loss=True)\n",
    "        print(f'Validation loss: {loss.item()}')\n",
    "    return loss.item()\n",
    "\n",
    "def save_checkpoint(epoch: int):\n",
    "    checkpoint_name = f'amadeus-performer-{format_time(start_time)}-{epoch}.pt'\n",
    "    Path(os.path.join(artifacts_dir, 'checkpoints')).mkdir(parents=True, exist_ok=True)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, os.path.join(artifacts_dir, 'checkpoints', checkpoint_name))\n",
    "    print(f'Saved checkpoint: {checkpoint_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting train on device: cuda\n",
      "Training on 10 epochs with batch size of 1\n",
      "Validating every 10 and saving every 0\n",
      "\n",
      "Training epoch #1 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 33.662s): AverageLoss: 5.8133\n",
      "Epoch 1 took 53.251s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #2 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 35.862s): AverageLoss: 4.5582\n",
      "Epoch 2 took 69.591s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #3 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 34.979s): AverageLoss: 3.8155\n",
      "Epoch 3 took 57.568s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #4 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 32.824s): AverageLoss: 3.7973\n",
      "Epoch 4 took 53.463s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #5 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 33.294s): AverageLoss: 3.3580\n",
      "Epoch 5 took 59.282s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #6 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 33.244s): AverageLoss: 4.1407\n",
      "Epoch 6 took 45.296s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #7 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 33.364s): AverageLoss: 3.2715\n",
      "Epoch 7 took 65.581s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #8 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 32.878s): AverageLoss: 2.2137\n",
      "Epoch 8 took 58.496s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #9 of 10:\n",
      "========================\n",
      "  Iter 100 (Took 33.325s): AverageLoss: 3.2202\n",
      "Epoch 9 took 55.895s\n",
      "\n",
      "\n",
      "\n",
      "Training epoch #10 of 10:\n",
      "=========================\n",
      "  Iter 100 (Took 32.747s): AverageLoss: 2.7936\n",
      "Epoch 10 took 64.820s\n",
      "Validation loss: 2.917832374572754\n",
      "\n",
      "\n",
      "\n",
      "Finished training and saved model in models directory.\n"
     ]
    }
   ],
   "source": [
    "print(f'Starting train on device: {device}')\n",
    "print(f'Training on {train_epochs} epochs with batch size of {batch_size}')\n",
    "print(f'Validating every {validate_every} and saving every {save_every}\\n')\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    prompt = f'Training epoch #{epoch+1} of {train_epochs}:'\n",
    "    print(f'{prompt}\\n{\"=\" * len(prompt)}')\n",
    "\n",
    "    total = datetime.now()\n",
    "\n",
    "    total_loss = train(train_set)\n",
    "\n",
    "    if has_gradient:\n",
    "        client.increment('EPOCHS', 1)\n",
    "        client.gauge('LOSS_PER_EPOCH', total_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1} took {(datetime.now()-total).total_seconds():.3f}s')\n",
    "\n",
    "    if validate_every > 0 and (epoch + 1) % validate_every == 0:\n",
    "        validate_loss = validate(test_set)\n",
    "        if has_gradient:\n",
    "            client.gauge('VALIDATE_LOSS', validate_loss)\n",
    "\n",
    "    if save_every > 0 and (epoch + 1) % save_every == 0:\n",
    "        save_checkpoint(epoch + 1)\n",
    "\n",
    "    print('\\n\\n')\n",
    "\n",
    "Path(os.path.join(model_dir, 'models')).mkdir(parents=True, exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(model_dir, 'models', f'amadeus-performer-{format_time(start_time)}.pt'))\n",
    "print('Finished training and saved model in models directory.')"
   ]
  }
 ]
}