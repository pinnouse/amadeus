{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os, sys\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "import re\n",
    "import random\n",
    "from datetime import datetime\n",
    "from argparse import ArgumentParser, ArgumentTypeError\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from performer_pytorch import PerformerLM\n",
    "\n",
    "from tokenizers import BertWordPieceTokenizer, Encoding\n",
    "\n",
    "from torchviz import make_dot\n",
    "\n",
    "from adafactor import Adafactor\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "       return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('-o', '--o', default='./', dest='output', help='Location of output(s)')\n",
    "parser.add_argument('-c', '--use_cuda', type=str2bool, dest='use_cuda', default=True, help='Use cuda if cuda supported')\n",
    "parser.add_argument('-a', '--artifacts', dest='artifacts', default='./', help='Directory to save artifacts such as checkpoints')\n",
    "parser.add_argument('-e', '--epochs', type=int, dest='train_epochs', default=1, help='Number of epochs to train on')\n",
    "parser.add_argument('-p', '--print_every', type=int, dest='print_every', default=100, help='After how many iterations to print a status')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "use_cuda = args.use_cuda\n",
    "\n",
    "device = 'cuda' if torch.has_cuda and use_cuda else 'cpu'\n",
    "\n",
    "model_dir = args.output\n",
    "artifacts_dir = args.artifacts\n",
    "Path(os.path.join(artifacts_dir, 'checkpoints')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_epochs = max(args.train_epochs, 1)\n",
    "print_every = max(args.print_every, 1)\n",
    "\n",
    "tokenizer = BertWordPieceTokenizer('data/bert-base-uncased-vocab.txt', lowercase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing\n",
    "Parse through subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_TOKEN = '<sos>'\n",
    "EOS_TOKEN = '<eos>'\n",
    "UNK_TOKEN = '<unk>'\n",
    "PAD_TOKEN = '<pad>'\n",
    "SEP_TOKEN = '<sep>'\n",
    "\n",
    "multiplier = [60, 60 * 60, 24 * 60 * 60]\n",
    "def get_time(timestr: str) -> int:\n",
    "    time = timestr.split(':')\n",
    "    final_time = 0\n",
    "    ms = float(time[-1]) * 1000\n",
    "    final_time += int(ms)\n",
    "    for i in range(len(time)-2):\n",
    "        t = time[-2-i]\n",
    "        final_time += multiplier[i] * int(t)\n",
    "    return final_time\n",
    "\n",
    "normalize_pattern = re.compile(r'(\\{[\\\\\\*][\\w\\(\\)\\\\\\,\\*]*|\\})', re.M)\n",
    "sub_space = re.compile(r'(\\{|\\\\[nN])', re.M)\n",
    "insert_space = re.compile(r'([\\w\\\"])([\\.\\!\\,\\?])')\n",
    "def normalize_text(text: str) -> str:\n",
    "    text = normalize_pattern.sub('', text)\n",
    "    text = sub_space.sub(' ', text)\n",
    "    text = re.sub(r'([\\'\\\"])', r' \\1 ', text)\n",
    "    text = re.sub(r'([\\.\\!\\?])(\\w)', r'\\1 \\2', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return insert_space.sub(r'\\1 \\2', text)\n",
    "\n",
    "number_match = re.compile(r'\\d+')\n",
    "def match_num(text: str) -> int:\n",
    "    x = number_match.findall(text)\n",
    "    return int(x[0] if len(x) > 0 else 0)\n",
    "\n",
    "class ParsedVocab:\n",
    "    \"\"\"The parsed vocabulary.\"\"\"\n",
    "\n",
    "    def __init__(self, words: List[Tuple[str, int]], longest: int = 0):\n",
    "        words.sort(key=lambda x : x[1], reverse=True)\n",
    "        # words = [('<sos>', 1), ('<eos>', 1)] + words\n",
    "        words = [(PAD_TOKEN, 0), (UNK_TOKEN, 0), (SEP_TOKEN, 0)] + words\n",
    "        self._word2freq = words\n",
    "        self._word2ind = {}\n",
    "        self._words = list(map(lambda x: x[0], words))\n",
    "        self._longest = longest\n",
    "\n",
    "        for i, (w, _) in enumerate(words):\n",
    "            self._word2ind[w] = i\n",
    "\n",
    "    def __getitem__(self, i) -> str:\n",
    "        return self._words[i]\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f'Parsed Vocabulary ({len(self._words)} words)'\n",
    "    \n",
    "    def get_words(self) -> List[str]:\n",
    "        return self._words\n",
    "    \n",
    "    def get_index(self, word) -> int:\n",
    "        if word in self._word2ind:\n",
    "            return self._word2ind[word]\n",
    "        return -1\n",
    "\n",
    "    def sen_to_seq(self, sentence: str, seq_len: int = 0, add_tokens: bool = True, add_pad: bool = False) -> List[int]:\n",
    "        sentence = normalize_text(sentence)\n",
    "        if seq_len <= 0:\n",
    "            seq_len = self._longest\n",
    "        l = []\n",
    "        if add_tokens:\n",
    "            sentence = f'{SOS_TOKEN} {sentence}'\n",
    "        s = sentence.split()\n",
    "        for i in range(min(len(s), seq_len - add_tokens)):\n",
    "            word = s[i]\n",
    "            if word in self._word2ind:\n",
    "                l.append(self._word2ind[word])\n",
    "            else:\n",
    "                l.append(self._word2ind[UNK_TOKEN])\n",
    "        if add_tokens:\n",
    "            l += [self._word2ind[EOS_TOKEN]]\n",
    "        if len(s) < seq_len and add_pad:\n",
    "            l += [self._word2ind[PAD_TOKEN]] * (seq_len - len(l))\n",
    "        return l\n",
    "\n",
    "    def conv_to_seq(self, conversation: List[Dict[str, object]], max_seq_len: int = 0) -> List[int]:\n",
    "        l = [self._word2ind[SOS_TOKEN]]\n",
    "        for conv in conversation:\n",
    "            l.extend(self.sen_to_seq(conv['line'], add_tokens=False))\n",
    "            l.append(self._word2ind[SEP_TOKEN])\n",
    "\n",
    "        if len(l) > 0:\n",
    "            l = l[:max_seq_len]\n",
    "            l[-1] = self._word2ind[EOS_TOKEN]\n",
    "        l += [self._word2ind[PAD_TOKEN]] * (max_seq_len - len(l))\n",
    "        return l\n",
    "        \n",
    "\n",
    "    def gen_mask(self, tokenized_sentence: List[int]) -> List[bool]:\n",
    "        \"\"\"Creates a mask for the given tokenized sentence.\n",
    "\n",
    "        >>> pv = ParsedVocab([('<sos>', 0), ('<eos>', 0), ('hi', 0)])\n",
    "        >>> x = pv.sen_to_seq('<sos> hi <eos> <unk> <unk>', )\n",
    "        >>> pv.gen_mask(x)\n",
    "        [1, 1, 1, 0, 0]\n",
    "        \"\"\"\n",
    "        l = [True] * len(tokenized_sentence)\n",
    "        i = len(tokenized_sentence) - 1\n",
    "        while i >= 0 and tokenized_sentence[i] == self._word2ind[PAD_TOKEN]:\n",
    "            l[i] = False\n",
    "            i -= 1\n",
    "        return l\n",
    "\n",
    "class Vocab:\n",
    "    \"\"\"Regulard vocabulary for holding the conversations and number of words.\"\"\"\n",
    "\n",
    "    DEFAULT_CONTEXT = 'default'\n",
    "\n",
    "    def __init__(self, conversation_depth: int = 4):\n",
    "        self.words = {}\n",
    "        self._context = Vocab.DEFAULT_CONTEXT\n",
    "        self.conversations = {}\n",
    "        self._held_conversations = {}\n",
    "        self.conversation_depth = conversation_depth\n",
    "        self.longest = 0\n",
    "        self.longest_tokenized = 0\n",
    "\n",
    "    def add_word(self, word: str) -> None:\n",
    "        word = word.lower()\n",
    "        if not word in self.words:\n",
    "            self.words[word] = 0\n",
    "        self.words[word] += 1\n",
    "\n",
    "    def add_sentence(self, sentence: str) -> None:\n",
    "        sentence = f'{SOS_TOKEN} {sentence} {EOS_TOKEN}'\n",
    "        [self.add_word(s) for s in sentence.split()]\n",
    "\n",
    "    def switch_context(self, new_context: str) -> None:\n",
    "        if self._context in self._held_conversations and len(self._held_conversations[self._context]) > self.conversation_depth:\n",
    "            self.conversations[self._context].append(self._held_conversations[self._context][\n",
    "                -self.conversation_depth:\n",
    "            ])\n",
    "        self._context = new_context\n",
    "\n",
    "    def add_conversation(self, conversation: Dict[str, object]) -> None:\n",
    "        if not self._context in self.conversations:\n",
    "            self.conversations[self._context] = []\n",
    "            self._held_conversations[self._context] = [conversation]\n",
    "            return\n",
    "        self.add_line(conversation)\n",
    "        lc = self._held_conversations[self._context][-1]\n",
    "        line = lc['line'].split()\n",
    "        if len(line) > self.longest:\n",
    "            self.longest = len(line)\n",
    "        tokenized = tokenizer.encode(lc['line'])\n",
    "        if len(tokenized.ids) > self.longest_tokenized:\n",
    "            self.longest_tokenized = len(tokenized.ids)\n",
    "    \n",
    "    def add_line(self, conversation: Dict[str, object]) -> bool:\n",
    "        if not self._context in self._held_conversations or len(self._held_conversations[self._context]) == 0:\n",
    "            self._held_conversations[self._context] = [conversation]\n",
    "            return True\n",
    "        hc = self._held_conversations[self._context] # Held Conversation\n",
    "        lc = hc[-1] # Last conversation\n",
    "        # Same speaker\n",
    "        if (len(lc['speaker']) > 0 and lc['speaker'] == conversation['speaker']) or \\\n",
    "            (len(lc['speaker']) == 0 and len(conversation['speaker']) == 0 and len(conversation['line']) > 0 and conversation['line'][0].islower()) and \\\n",
    "            conversation['when'] - lc['when'] < 1000 * 60 * 1.5:\n",
    "            hc[-1]['when'] = conversation['when']\n",
    "            hc[-1]['line'] += f\" {conversation['line']}\"\n",
    "            return False\n",
    "        if len(self._held_conversations[self._context]) >= 2:\n",
    "            self.conversations[self._context].append(self._held_conversations[self._context][\n",
    "                -min(self.conversation_depth, len(hc)):\n",
    "            ])\n",
    "        hc.append(conversation)\n",
    "        return True\n",
    "\n",
    "    def parse_vocab(self) -> ParsedVocab:\n",
    "        words = list(self.words.items())\n",
    "        return ParsedVocab(words, self.longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parsing folder: ditfxx_subs\n",
      "  Opening file: DitFXX (1).ass\n",
      "  Opening file: DitFXX (2).ass\n",
      "  Opening file: DitFXX (3).ass\n",
      "  Opening file: DitFXX (4).ass\n",
      "  Opening file: DitFXX (5).ass\n",
      "  Opening file: DitFXX (6).ass\n",
      "  Opening file: DitFXX (7).ass\n",
      "  Opening file: DitFXX (8).ass\n",
      "  Opening file: DitFXX (9).ass\n",
      "  Opening file: DitFXX (10).ass\n",
      "  Opening file: DitFXX (11).ass\n",
      "  Opening file: DitFXX (12).ass\n",
      "  Opening file: DitFXX (13).ass\n",
      "  Opening file: DitFXX (14).ass\n",
      "  Opening file: DitFXX (15).ass\n",
      "  Opening file: DitFXX (16).ass\n",
      "  Opening file: DitFXX (17).ass\n",
      "  Opening file: DitFXX (18).ass\n",
      "  Opening file: DitFXX (19).ass\n",
      "  Opening file: DitFXX (20).ass\n",
      "  Opening file: DitFXX (21).ass\n",
      "  Opening file: DitFXX (22).ass\n",
      "  Opening file: DitFXX (23).ass\n",
      "Parsing folder: steins_gate_subs\n",
      "  Opening file: Steins;Gate 01.ass\n",
      "  Opening file: Steins;Gate 02.ass\n",
      "  Opening file: Steins;Gate 03.ass\n",
      "  Opening file: Steins;Gate 04.ass\n",
      "  Opening file: Steins;Gate 05.ass\n",
      "  Opening file: Steins;Gate 06.ass\n",
      "  Opening file: Steins;Gate 07.ass\n",
      "  Opening file: Steins;Gate 08.ass\n",
      "  Opening file: Steins;Gate 09.ass\n",
      "  Opening file: Steins;Gate 10.ass\n",
      "  Opening file: Steins;Gate 11.ass\n",
      "  Opening file: Steins;Gate 12.ass\n",
      "  Opening file: Steins;Gate 13.ass\n",
      "  Opening file: Steins;Gate 14.ass\n",
      "  Opening file: Steins;Gate 15.ass\n",
      "  Opening file: Steins;Gate 16.ass\n",
      "  Opening file: Steins;Gate 17.ass\n",
      "  Opening file: Steins;Gate 18.ass\n",
      "  Opening file: Steins;Gate 19.ass\n",
      "  Opening file: Steins;Gate 20.ass\n",
      "  Opening file: Steins;Gate 21.ass\n",
      "  Opening file: Steins;Gate 22.ass\n",
      "  Opening file: Steins;Gate 23.ass\n",
      "  Opening file: Steins;Gate 24.ass\n",
      "  Opening file: Steins;Gate 25.ass\n",
      "Done! Num conversations: 12094, num words: 5485, longest convo: 185\n"
     ]
    }
   ],
   "source": [
    "FOLDERS = ['ditfxx_subs', 'steins_gate_subs']\n",
    "CONVERSATION_DEPTH = 4\n",
    "\n",
    "vocab = Vocab(CONVERSATION_DEPTH)\n",
    "\n",
    "for folder in FOLDERS:\n",
    "    dir = os.listdir(os.path.join('data', folder))\n",
    "    dir.sort(key=match_num)\n",
    "    print(f'Parsing folder: {folder}')\n",
    "    for f in dir:\n",
    "        filepath = os.path.join(os.getcwd(), 'data', folder, f)\n",
    "        if not os.path.isfile(filepath): continue\n",
    "        print(f'  Opening file: {f}')\n",
    "        with open(filepath, 'r', encoding='utf-8', errors='ignore') as sub_file:\n",
    "            is_event = False\n",
    "            line = True\n",
    "            while not is_event and line:\n",
    "                line = sub_file.readline()\n",
    "                if not line: break\n",
    "                if line.rstrip() == \"[Events]\":\n",
    "                    is_event = True\n",
    "            current_format = False\n",
    "            current_conversation = []\n",
    "            \n",
    "            vocab.switch_context(f)\n",
    "            line = True\n",
    "            # for line in sub_file.readlines():\n",
    "            while line:\n",
    "                try:\n",
    "                    line = sub_file.readline()\n",
    "                except UnicodeDecodeError:\n",
    "                    print('    Error decoding a line, skipped.')\n",
    "                if line.startswith('Format:'):\n",
    "                    line = line[len('Format:'):].strip().split(', ')\n",
    "                    current_format = line\n",
    "                    continue\n",
    "                if current_format == False or not line.startswith('Dialogue:'): continue\n",
    "                line = line[len('Dialogue:'):].strip().split(',')\n",
    "                line[len(current_format)-1] = ','.join(line[len(current_format)-1:])\n",
    "                dialogue = dict(zip(current_format, line))\n",
    "                if not dialogue['Style'] in ['main', 'Default']: continue\n",
    "                # Extract variables\n",
    "                speaker = dialogue['Name']\n",
    "                text = normalize_text(dialogue['Text'])\n",
    "                time = get_time(dialogue['Start'])\n",
    "\n",
    "                # if len(current_conversation) > 0 and time - current_conversation[-1]['when'] > 1000 * 60 * 2:\n",
    "                #     current_conversation = []\n",
    "                # if len(current_conversation) > 0 and ((len(speaker) > 0 and current_conversation[-1]['speaker'] == speaker) or \n",
    "                # (len(speaker) == 0 and len(dialogue['Text']) > 0 and dialogue['Text'][0].islower())):\n",
    "                #     current_conversation[-1]['line'] += f' {text}'\n",
    "                #     current_conversation[-1]['when'] = time\n",
    "                # else:\n",
    "                #     vocab.add_conversation(current_conversation)\n",
    "                #     current_conversation.append({\n",
    "                #         'speaker': speaker,\n",
    "                #         'line': text,\n",
    "                #         'when': time\n",
    "                #     })\n",
    "                # if len(current_conversation) > CONVERSATION_DEPTH:\n",
    "                #     current_conversation = current_conversation[CONVERSATION_DEPTH - len(current_conversation):]\n",
    "                # if len(current_conversation) == 1:\n",
    "                #     continue\n",
    "                vocab.add_conversation({\n",
    "                    'speaker': speaker,\n",
    "                    'line': text,\n",
    "                    'when': time\n",
    "                })\n",
    "                vocab.add_sentence(text)\n",
    "            \n",
    "# tokenizer.enable_padding(length=vocab.longest_tokenized)\n",
    "pv = vocab.parse_vocab()\n",
    "convos = 0\n",
    "for k, c in vocab.conversations.items():\n",
    "    convos += len(c)\n",
    "print(f'Done! Num conversations: {convos}, num words: {len(pv.get_words())}, longest convo: {vocab.longest_tokenized}')\n",
    "# print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n['I wanna take a bath .', 'Not again . Show some self-control .']\n['[CLS]', 'i', 'wanna', 'take', 'a', 'bath', '.', '[SEP]', '[CLS]', 'not', 'again', '.', 'show', 'some', 'self', '-', 'control', '.', '[SEP]']\n\n['I wanna take a bath .', 'Not again . Show some self-control .', 'Hey , how do I smell ?']\n['[CLS]', 'i', 'wanna', 'take', 'a', 'bath', '.', '[SEP]', '[CLS]', 'not', 'again', '.', 'show', 'some', 'self', '-', 'control', '.', '[SEP]', '[CLS]', 'hey', ',', 'how', 'do', 'i', 'smell', '?', '[SEP]']\n\n['I wanna take a bath .', 'Not again . Show some self-control .', 'Hey , how do I smell ?', \"Let him rest . He ' s drained after the last battle . Sheesh , what a high-maintenance girl .\"]\n['[CLS]', 'i', 'wanna', 'take', 'a', 'bath', '.', '[SEP]', '[CLS]', 'not', 'again', '.', 'show', 'some', 'self', '-', 'control', '.', '[SEP]', '[CLS]', 'hey', ',', 'how', 'do', 'i', 'smell', '?', '[SEP]', '[CLS]', 'let', 'him', 'rest', '.', 'he', \"'\", 's', 'drained', 'after', 'the', 'last', 'battle', '.', 'she', '##esh', ',', 'what', 'a', 'high', '-', 'maintenance', 'girl', '.', '[SEP]']\n\n['Not again . Show some self-control .', 'Hey , how do I smell ?', \"Let him rest . He ' s drained after the last battle . Sheesh , what a high-maintenance girl .\", 'Does Plantation 13 have an ocean ?']\n['[CLS]', 'not', 'again', '.', 'show', 'some', 'self', '-', 'control', '.', '[SEP]', '[CLS]', 'hey', ',', 'how', 'do', 'i', 'smell', '?', '[SEP]', '[CLS]', 'let', 'him', 'rest', '.', 'he', \"'\", 's', 'drained', 'after', 'the', 'last', 'battle', '.', 'she', '##esh', ',', 'what', 'a', 'high', '-', 'maintenance', 'girl', '.', '[SEP]', '[CLS]', 'does', 'plantation', '13', 'have', 'an', 'ocean', '?', '[SEP]']\n\n['Hey , how do I smell ?', \"Let him rest . He ' s drained after the last battle . Sheesh , what a high-maintenance girl .\", 'Does Plantation 13 have an ocean ?', 'An ocean ?']\n['[CLS]', 'hey', ',', 'how', 'do', 'i', 'smell', '?', '[SEP]', '[CLS]', 'let', 'him', 'rest', '.', 'he', \"'\", 's', 'drained', 'after', 'the', 'last', 'battle', '.', 'she', '##esh', ',', 'what', 'a', 'high', '-', 'maintenance', 'girl', '.', '[SEP]', '[CLS]', 'does', 'plantation', '13', 'have', 'an', 'ocean', '?', '[SEP]', '[CLS]', 'an', 'ocean', '?', '[SEP]']\n30522\n{'length': None, 'pad_to_multiple_of': None, 'pad_id': 0, 'pad_token': '[PAD]', 'pad_type_id': 0, 'direction': 'right'}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'speaker': 'Z2', 'line': 'I wanna take a bath .', 'when': 150},\n",
       " {'speaker': 'Franxx',\n",
       "  'line': 'Not again . Show some self-control .',\n",
       "  'when': 2160}]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "x = list(vocab.conversations)\n",
    "c = vocab.conversations[x[0]]\n",
    "\n",
    "for cc in c[:5]:\n",
    "    l = [x['line'] for x in cc]\n",
    "    print(f'\\n{l}')\n",
    "    output = tokenizer.encode_batch(l)\n",
    "    # print([o.tokens for o in output])\n",
    "    # print([o.tokens[0 if i == 0 else 1:] for i, o in enumerate(output)])\n",
    "    # cat = sum([o.ids[0 if i == 0 else 1:] for i, o in enumerate(output)], [])\n",
    "    # output[1].pad(100)\n",
    "    # print(output[0].merge(output[1:2]).ids)\n",
    "    # print(tokenizer.decode(cat))\n",
    "    # output = tokenizer.encode(l[0], pair=l[1])\n",
    "    output = Encoding.merge(output, growing_offsets=False)\n",
    "    print(output.tokens)\n",
    "\n",
    "print(tokenizer.get_vocab_size())\n",
    "\n",
    "tokenizer.enable_padding()\n",
    "print(tokenizer.padding)\n",
    "\n",
    "c[0][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model\n",
    "Defining the actual AI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 555, 30522])\ntorch.Size([1, 555])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<graphviz.dot.Digraph at 0x21a80688af0>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n -->\r\n<!-- Title: %3 Pages: 1 -->\r\n<svg width=\"464pt\" height=\"822pt\"\r\n viewBox=\"0.00 0.00 464.00 822.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 818)\">\r\n<title>%3</title>\r\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-818 460,-818 460,4 -4,4\"/>\r\n<!-- 2312846681232 -->\r\n<g id=\"node1\" class=\"node\"><title>2312846681232</title>\r\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"401.5,-21 305.5,-21 305.5,-0 401.5,-0 401.5,-21\"/>\r\n<text text-anchor=\"middle\" x=\"353.5\" y=\"-7.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MeanBackward0</text>\r\n</g>\r\n<!-- 2312846683200 -->\r\n<g id=\"node2\" class=\"node\"><title>2312846683200</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"398.5,-78 308.5,-78 308.5,-57 398.5,-57 398.5,-78\"/>\r\n<text text-anchor=\"middle\" x=\"353.5\" y=\"-64.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">AddBackward0</text>\r\n</g>\r\n<!-- 2312846683200&#45;&gt;2312846681232 -->\r\n<g id=\"edge1\" class=\"edge\"><title>2312846683200&#45;&gt;2312846681232</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M353.5,-56.9197C353.5,-49.9083 353.5,-40.1442 353.5,-31.4652\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"357,-31.3408 353.5,-21.3408 350,-31.3409 357,-31.3408\"/>\r\n</g>\r\n<!-- 2312846660320 -->\r\n<g id=\"node3\" class=\"node\"><title>2312846660320</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"353,-141.5 234,-141.5 234,-120.5 353,-120.5 353,-141.5\"/>\r\n<text text-anchor=\"middle\" x=\"293.5\" y=\"-127.9\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">UnsafeViewBackward</text>\r\n</g>\r\n<!-- 2312846660320&#45;&gt;2312846683200 -->\r\n<g id=\"edge2\" class=\"edge\"><title>2312846660320&#45;&gt;2312846683200</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M302.875,-120.391C311.98,-111.058 325.997,-96.6902 336.976,-85.4374\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"339.515,-87.8468 343.993,-78.2449 334.504,-82.9586 339.515,-87.8468\"/>\r\n</g>\r\n<!-- 2312846660608 -->\r\n<g id=\"node4\" class=\"node\"><title>2312846660608</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"335,-205 252,-205 252,-184 335,-184 335,-205\"/>\r\n<text text-anchor=\"middle\" x=\"293.5\" y=\"-191.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MmBackward</text>\r\n</g>\r\n<!-- 2312846660608&#45;&gt;2312846660320 -->\r\n<g id=\"edge3\" class=\"edge\"><title>2312846660608&#45;&gt;2312846660320</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M293.5,-183.891C293.5,-175.366 293.5,-162.639 293.5,-151.923\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"297,-151.745 293.5,-141.745 290,-151.745 297,-151.745\"/>\r\n</g>\r\n<!-- 2312846662912 -->\r\n<g id=\"node5\" class=\"node\"><title>2312846662912</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"288.5,-262 200.5,-262 200.5,-241 288.5,-241 288.5,-262\"/>\r\n<text text-anchor=\"middle\" x=\"244.5\" y=\"-248.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">ViewBackward</text>\r\n</g>\r\n<!-- 2312846662912&#45;&gt;2312846660608 -->\r\n<g id=\"edge4\" class=\"edge\"><title>2312846662912&#45;&gt;2312846660608</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M253.035,-240.92C259.906,-233.207 269.745,-222.164 278,-212.898\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"280.694,-215.136 284.733,-205.341 275.467,-210.479 280.694,-215.136\"/>\r\n</g>\r\n<!-- 2313724832016 -->\r\n<g id=\"node6\" class=\"node\"><title>2313724832016</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"308,-325.5 161,-325.5 161,-304.5 308,-304.5 308,-325.5\"/>\r\n<text text-anchor=\"middle\" x=\"234.5\" y=\"-311.9\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">NativeLayerNormBackward</text>\r\n</g>\r\n<!-- 2313724832016&#45;&gt;2312846662912 -->\r\n<g id=\"edge5\" class=\"edge\"><title>2313724832016&#45;&gt;2312846662912</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M236.063,-304.391C237.449,-295.866 239.518,-283.139 241.26,-272.423\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"244.765,-272.677 242.915,-262.245 237.856,-271.553 244.765,-272.677\"/>\r\n</g>\r\n<!-- 2313724833024 -->\r\n<g id=\"node7\" class=\"node\"><title>2313724833024</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"168.5,-395.5 78.5,-395.5 78.5,-374.5 168.5,-374.5 168.5,-395.5\"/>\r\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-381.9\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">SumBackward1</text>\r\n</g>\r\n<!-- 2313724833024&#45;&gt;2313724832016 -->\r\n<g id=\"edge6\" class=\"edge\"><title>2313724833024&#45;&gt;2313724832016</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M139.404,-374.257C157.972,-362.882 188.879,-343.948 210.399,-330.765\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"212.285,-333.714 218.984,-325.505 208.628,-327.745 212.285,-333.714\"/>\r\n</g>\r\n<!-- 2313724832784 -->\r\n<g id=\"node8\" class=\"node\"><title>2313724832784</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"168.5,-459 78.5,-459 78.5,-438 168.5,-438 168.5,-459\"/>\r\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-445.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">StackBackward</text>\r\n</g>\r\n<!-- 2313724832784&#45;&gt;2313724833024 -->\r\n<g id=\"edge7\" class=\"edge\"><title>2313724832784&#45;&gt;2313724833024</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M123.5,-437.891C123.5,-429.366 123.5,-416.639 123.5,-405.923\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"127,-405.745 123.5,-395.745 120,-405.745 127,-405.745\"/>\r\n</g>\r\n<!-- 2313724831968 -->\r\n<g id=\"node9\" class=\"node\"><title>2313724831968</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"165.5,-516 81.5,-516 81.5,-495 165.5,-495 165.5,-516\"/>\r\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-502.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">SplitBackward</text>\r\n</g>\r\n<!-- 2313724831968&#45;&gt;2313724832784 -->\r\n<g id=\"edge8\" class=\"edge\"><title>2313724831968&#45;&gt;2313724832784</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M118.233,-494.92C116.855,-487.908 116.437,-478.144 116.98,-469.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"120.479,-469.684 118.183,-459.341 113.528,-468.858 120.479,-469.684\"/>\r\n</g>\r\n<!-- 2313724831968&#45;&gt;2313724832784 -->\r\n<g id=\"edge17\" class=\"edge\"><title>2313724831968&#45;&gt;2313724832784</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M128.767,-494.92C130.145,-487.908 130.563,-478.144 130.02,-469.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"133.472,-468.858 128.817,-459.341 126.521,-469.684 133.472,-468.858\"/>\r\n</g>\r\n<!-- 2313255079648 -->\r\n<g id=\"node10\" class=\"node\"><title>2313255079648</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"201.5,-573 45.5,-573 45.5,-552 201.5,-552 201.5,-573\"/>\r\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-559.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">_ReversibleFunctionBackward</text>\r\n</g>\r\n<!-- 2313255079648&#45;&gt;2313724831968 -->\r\n<g id=\"edge9\" class=\"edge\"><title>2313255079648&#45;&gt;2313724831968</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M123.5,-551.92C123.5,-544.908 123.5,-535.144 123.5,-526.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"127,-526.341 123.5,-516.341 120,-526.341 127,-526.341\"/>\r\n</g>\r\n<!-- 2313724833360 -->\r\n<g id=\"node11\" class=\"node\"><title>2313724833360</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"163.5,-630 83.5,-630 83.5,-609 163.5,-609 163.5,-630\"/>\r\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-616.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">CatBackward</text>\r\n</g>\r\n<!-- 2313724833360&#45;&gt;2313255079648 -->\r\n<g id=\"edge10\" class=\"edge\"><title>2313724833360&#45;&gt;2313255079648</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M123.5,-608.92C123.5,-601.908 123.5,-592.144 123.5,-583.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"127,-583.341 123.5,-573.341 120,-583.341 127,-583.341\"/>\r\n</g>\r\n<!-- 2313724830576 -->\r\n<g id=\"node12\" class=\"node\"><title>2313724830576</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"168.5,-687 78.5,-687 78.5,-666 168.5,-666 168.5,-687\"/>\r\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-673.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">AddBackward0</text>\r\n</g>\r\n<!-- 2313724830576&#45;&gt;2313724833360 -->\r\n<g id=\"edge11\" class=\"edge\"><title>2313724830576&#45;&gt;2313724833360</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M118.233,-665.92C116.855,-658.908 116.437,-649.144 116.98,-640.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"120.479,-640.684 118.183,-630.341 113.528,-639.858 120.479,-640.684\"/>\r\n</g>\r\n<!-- 2313724830576&#45;&gt;2313724833360 -->\r\n<g id=\"edge16\" class=\"edge\"><title>2313724830576&#45;&gt;2313724833360</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M128.767,-665.92C130.145,-658.908 130.563,-649.144 130.02,-640.465\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"133.472,-639.858 128.817,-630.341 126.521,-640.684 133.472,-639.858\"/>\r\n</g>\r\n<!-- 2312846670432 -->\r\n<g id=\"node13\" class=\"node\"><title>2312846670432</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"115,-744 0,-744 0,-723 115,-723 115,-744\"/>\r\n<text text-anchor=\"middle\" x=\"57.5\" y=\"-730.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">EmbeddingBackward</text>\r\n</g>\r\n<!-- 2312846670432&#45;&gt;2313724830576 -->\r\n<g id=\"edge12\" class=\"edge\"><title>2312846670432&#45;&gt;2313724830576</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M68.9963,-722.92C78.6253,-714.896 92.5807,-703.266 103.96,-693.784\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"106.249,-696.431 111.691,-687.341 101.768,-691.054 106.249,-696.431\"/>\r\n</g>\r\n<!-- 2312846668320 -->\r\n<g id=\"node14\" class=\"node\"><title>2312846668320</title>\r\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"107.5,-814 7.5,-814 7.5,-780 107.5,-780 107.5,-814\"/>\r\n<text text-anchor=\"middle\" x=\"57.5\" y=\"-800.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">token_emb.weight</text>\r\n<text text-anchor=\"middle\" x=\"57.5\" y=\"-787.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (30522, 512)</text>\r\n</g>\r\n<!-- 2312846668320&#45;&gt;2312846670432 -->\r\n<g id=\"edge13\" class=\"edge\"><title>2312846668320&#45;&gt;2312846670432</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M57.5,-779.842C57.5,-772.012 57.5,-762.54 57.5,-754.282\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"61.0001,-754.042 57.5,-744.042 54.0001,-754.042 61.0001,-754.042\"/>\r\n</g>\r\n<!-- 2312846669040 -->\r\n<g id=\"node15\" class=\"node\"><title>2312846669040</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"248,-744 133,-744 133,-723 248,-723 248,-744\"/>\r\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-730.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">EmbeddingBackward</text>\r\n</g>\r\n<!-- 2312846669040&#45;&gt;2313724830576 -->\r\n<g id=\"edge14\" class=\"edge\"><title>2312846669040&#45;&gt;2313724830576</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M178.829,-722.92C169.055,-714.896 154.888,-703.266 143.337,-693.784\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"145.438,-690.981 135.488,-687.341 140.996,-696.391 145.438,-690.981\"/>\r\n</g>\r\n<!-- 2312846671200 -->\r\n<g id=\"node16\" class=\"node\"><title>2312846671200</title>\r\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"236,-814 145,-814 145,-780 236,-780 236,-814\"/>\r\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-800.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">pos_emb.weight</text>\r\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-787.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (555, 512)</text>\r\n</g>\r\n<!-- 2312846671200&#45;&gt;2312846669040 -->\r\n<g id=\"edge15\" class=\"edge\"><title>2312846671200&#45;&gt;2312846669040</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M190.5,-779.842C190.5,-772.012 190.5,-762.54 190.5,-754.282\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"194,-754.042 190.5,-744.042 187,-754.042 194,-754.042\"/>\r\n</g>\r\n<!-- 2313724831584 -->\r\n<g id=\"node17\" class=\"node\"><title>2313724831584</title>\r\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"282.5,-402 186.5,-402 186.5,-368 282.5,-368 282.5,-402\"/>\r\n<text text-anchor=\"middle\" x=\"234.5\" y=\"-388.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">to_logits.0.weight</text>\r\n<text text-anchor=\"middle\" x=\"234.5\" y=\"-375.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (512)</text>\r\n</g>\r\n<!-- 2313724831584&#45;&gt;2313724832016 -->\r\n<g id=\"edge18\" class=\"edge\"><title>2313724831584&#45;&gt;2313724832016</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M234.5,-367.885C234.5,-358.309 234.5,-346.088 234.5,-335.912\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"238,-335.895 234.5,-325.895 231,-335.895 238,-335.895\"/>\r\n</g>\r\n<!-- 2313724831776 -->\r\n<g id=\"node18\" class=\"node\"><title>2313724831776</title>\r\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"386,-402 301,-402 301,-368 386,-368 386,-402\"/>\r\n<text text-anchor=\"middle\" x=\"343.5\" y=\"-388.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">to_logits.0.bias</text>\r\n<text text-anchor=\"middle\" x=\"343.5\" y=\"-375.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (512)</text>\r\n</g>\r\n<!-- 2313724831776&#45;&gt;2313724832016 -->\r\n<g id=\"edge19\" class=\"edge\"><title>2313724831776&#45;&gt;2313724832016</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M317.669,-367.885C299.763,-356.714 276.086,-341.943 258.575,-331.019\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"260.38,-328.02 250.043,-325.696 256.675,-333.959 260.38,-328.02\"/>\r\n</g>\r\n<!-- 2312846661568 -->\r\n<g id=\"node19\" class=\"node\"><title>2312846661568</title>\r\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"399,-262 328,-262 328,-241 399,-241 399,-262\"/>\r\n<text text-anchor=\"middle\" x=\"363.5\" y=\"-248.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">TBackward</text>\r\n</g>\r\n<!-- 2312846661568&#45;&gt;2312846660608 -->\r\n<g id=\"edge20\" class=\"edge\"><title>2312846661568&#45;&gt;2312846660608</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M351.307,-240.92C341.094,-232.896 326.293,-221.266 314.225,-211.784\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"316.05,-208.767 306.025,-205.341 311.726,-214.271 316.05,-208.767\"/>\r\n</g>\r\n<!-- 2313724830768 -->\r\n<g id=\"node20\" class=\"node\"><title>2313724830768</title>\r\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"422.5,-332 326.5,-332 326.5,-298 422.5,-298 422.5,-332\"/>\r\n<text text-anchor=\"middle\" x=\"374.5\" y=\"-318.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">to_logits.1.weight</text>\r\n<text text-anchor=\"middle\" x=\"374.5\" y=\"-305.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (30522, 512)</text>\r\n</g>\r\n<!-- 2313724830768&#45;&gt;2312846661568 -->\r\n<g id=\"edge21\" class=\"edge\"><title>2313724830768&#45;&gt;2312846661568</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M371.61,-297.842C370.194,-289.923 368.477,-280.324 366.988,-272.001\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"370.413,-271.269 365.207,-262.042 363.522,-272.502 370.413,-271.269\"/>\r\n</g>\r\n<!-- 2312846660560 -->\r\n<g id=\"node21\" class=\"node\"><title>2312846660560</title>\r\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"456,-148 371,-148 371,-114 456,-114 456,-148\"/>\r\n<text text-anchor=\"middle\" x=\"413.5\" y=\"-134.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">to_logits.1.bias</text>\r\n<text text-anchor=\"middle\" x=\"413.5\" y=\"-121.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (30522)</text>\r\n</g>\r\n<!-- 2312846660560&#45;&gt;2312846683200 -->\r\n<g id=\"edge22\" class=\"edge\"><title>2312846660560&#45;&gt;2312846683200</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M397.736,-113.842C389.142,-105.033 378.52,-94.1458 369.839,-85.2474\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"372.298,-82.7556 362.809,-78.0419 367.287,-87.6439 372.298,-82.7556\"/>\r\n</g>\r\n</g>\r\n</svg>\r\n"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# 3 Sentences with 2 delims\n",
    "seq_len = vocab.longest_tokenized * (vocab.conversation_depth - 1)\n",
    "\n",
    "# Thanks to\n",
    "# https://github.com/lucidrains/performer-pytorch\n",
    "model = PerformerLM(\n",
    "    num_tokens=tokenizer.get_vocab_size(),\n",
    "    max_seq_len=seq_len,\n",
    "    dim=512,\n",
    "    depth=6,\n",
    "    heads=8,\n",
    "    causal=False,\n",
    "    nb_features=256,\n",
    "    generalized_attention=True,\n",
    "    kernel_fn=nn.ReLU(),\n",
    "    reversible=True,\n",
    "    ff_chunks=10,\n",
    "    use_scalenorm=False,\n",
    "    use_rezero=True\n",
    ")\n",
    "\n",
    "x = torch.randint(0, len(pv.get_words()), (1, seq_len))\n",
    "mask = torch.ones_like(x).bool()\n",
    "\n",
    "y = model(x, mask=mask)\n",
    "\n",
    "print(y.size())\n",
    "print(x.shape)\n",
    "\n",
    "make_dot(y.mean(), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adafactor(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "class ConversationIter:\n",
    "\n",
    "    def __init__(self, vocab: Vocab, parsed_vocab: ParsedVocab, max_seq_len: int):\n",
    "        self._vocab = vocab\n",
    "        self._parsed_vocab = parsed_vocab\n",
    "        self._context = random.choice(list(vocab.conversations))\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        self._i = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._context = random.choice(list(self._vocab.conversations))\n",
    "        self._i = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> Tuple[Encoding, Encoding]:\n",
    "        if self._i >= len(self._vocab.conversations[self._context]):\n",
    "            raise StopIteration\n",
    "        x = self._vocab.conversations[self._context][self._i]\n",
    "        l = [tokenizer.encode(y['line']) for y in x]\n",
    "        # i = Encoding.merge()\n",
    "        input = Encoding.merge(l[:-1])\n",
    "        target = l[-1]\n",
    "        input.pad(self._vocab.longest_tokenized)\n",
    "        target.pad(self._vocab.longest_tokenized)\n",
    "        # i = sum([j.ids[0 if i == 0 else 1:] for i, j in enumerate(l[-1])], [])\n",
    "        # t = l[-1].ids\n",
    "        # i.extend([tokenizer.pad_id] * (len(i) - vocab.longest_tokenized))\n",
    "        # input = torch.tensor()\n",
    "        # target = torch.tensor(l[-1].ids)\n",
    "        # input = torch.tensor(self._parsed_vocab.conv_to_seq(x[:-1], self.max_seq_len))\n",
    "        # target = torch.tensor(self._parsed_vocab.sen_to_seq(x[-1]['line'], seq_len=self.max_seq_len, add_pad=True))\n",
    "        self._i += 1\n",
    "        return input, target\n",
    "\n",
    "def train(conv_iter: ConversationIter):\n",
    "    model.train()\n",
    "    accrued_loss = 0\n",
    "    start = datetime.now()\n",
    "    for i, (input, target) in enumerate(conv_iter):\n",
    "        # mask = torch.tensor(pv.gen_mask(input))\n",
    "        mask = torch.tensor(input.attention_mask).bool()\n",
    "\n",
    "        input = torch.tensor(input.ids)\n",
    "        target = torch.tensor(target.ids)\n",
    "\n",
    "        input.to(device)\n",
    "        target.to(device)\n",
    "\n",
    "        input.unsqueeze_(0)\n",
    "        target.unsqueeze_(0)\n",
    "        mask.unsqueeze_(0)\n",
    "\n",
    "#         input = F.one_hot(input, len(pv.get_words()))\n",
    "#         input.transpose_(0, 1)\n",
    "\n",
    "#         print(input.shape, target.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input, mask=mask)\n",
    "#         output.transpose_(1, 2)\n",
    "        loss = criterion(output.squeeze(0), target.squeeze(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        accrued_loss += loss.item()\n",
    "        \n",
    "        if (i + 1) % print_every == 0:\n",
    "            print(f'  Iter {i+1} (Took {(datetime.now() - start).total_seconds():.3f}s): AverageLoss: {accrued_loss/print_every:.4f}')\n",
    "            accrued_loss = 0\n",
    "            start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training epoch #1 of 1:\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-705039d67580>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Training epoch #{epoch+1} of {train_epochs}:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch {epoch+1} took {(datetime.now()-total).total_seconds():.3f}s\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-a52596fb334c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(conv_iter)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;31m#         output.transpose_(1, 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_emb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPerformerLM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\reversible.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'f_args'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'g_args'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0m_ReversibleFunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\reversible.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, x, blocks, args)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\reversible.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, f_args, g_args)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mf_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mg_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\reversible.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, record_rng, set_rng, *args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mset_rng\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mrng_devices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPreScaleNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mFeedForward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\performer_pytorch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mFeedForward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    231\u001b[0m         )\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mSelfAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1676\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1678\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SAVE_EVERY = 5\n",
    "\n",
    "conv_iter = ConversationIter(vocab, pv, seq_len)\n",
    "\n",
    "def save_checkpoint(epoch: int):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, os.path.join(artifacts_dir, f'checkpoints/amadeus-performer-{epoch}.pt'))\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    print(f'Training epoch #{epoch+1} of {train_epochs}:')\n",
    "    total = datetime.now()\n",
    "    train(conv_iter)\n",
    "    print(f'Epoch {epoch+1} took {(datetime.now()-total).total_seconds():.3f}s\\n\\n')\n",
    "    \n",
    "    if (epoch + 1) % SAVE_EVERY == 0:\n",
    "        print('Saving checkpoint...')\n",
    "        save_checkpoint(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}