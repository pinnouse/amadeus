{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os, sys\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchviz import make_dot\n",
    "\n",
    "from adafactor import Adafactor\n",
    "\n",
    "device = 'cuda' if torch.has_cuda else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing\n",
    "Parse through subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_TOKEN = '<sos>'\n",
    "EOS_TOKEN = '<eos>'\n",
    "UNK_TOKEN = '<unk>'\n",
    "PAD_TOKEN = '<pad>'\n",
    "SEP_TOKEN = '<sep>'\n",
    "\n",
    "multiplier = [60, 60 * 60, 24 * 60 * 60]\n",
    "def get_time(timestr: str) -> int:\n",
    "    time = timestr.split(':')\n",
    "    final_time = 0\n",
    "    ms = float(time[-1]) * 1000\n",
    "    final_time += int(ms)\n",
    "    for i in range(len(time)-2):\n",
    "        t = time[-2-i]\n",
    "        final_time += multiplier[i] * int(t)\n",
    "    return final_time\n",
    "\n",
    "normalize_pattern = re.compile(r'(\\{[\\\\\\*][\\w\\(\\)\\\\\\,\\*]*|\\})', re.M)\n",
    "sub_space = re.compile(r'(\\{|\\\\[nN])', re.M)\n",
    "insert_space = re.compile(r'([\\w\\\"])([\\.\\!\\,\\?])')\n",
    "def normalize_text(text: str) -> str:\n",
    "    text = normalize_pattern.sub('', text)\n",
    "    text = sub_space.sub(' ', text)\n",
    "    text = re.sub(r'([\\'\\\"])', r' \\1 ', text)\n",
    "    text = re.sub(r'([\\.\\!\\?])(\\w)', r'\\1 \\2', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return insert_space.sub(r'\\1 \\2', text)\n",
    "\n",
    "number_match = re.compile(r'\\d+')\n",
    "def match_num(text: str) -> int:\n",
    "    x = number_match.findall(text)\n",
    "    return int(x[0] if len(x) > 0 else 0)\n",
    "\n",
    "class ParsedVocab:\n",
    "    \"\"\"The parsed vocabulary.\"\"\"\n",
    "\n",
    "    def __init__(self, words: List[Tuple[str, int]], longest: int = 0):\n",
    "        words.sort(key=lambda x : x[1], reverse=True)\n",
    "        # words = [('<sos>', 1), ('<eos>', 1)] + words\n",
    "        words = [(PAD_TOKEN, 0), (UNK_TOKEN, 0), (SEP_TOKEN, 0)] + words\n",
    "        self._word2freq = words\n",
    "        self._word2ind = {}\n",
    "        self._words = list(map(lambda x: x[0], words))\n",
    "        self._longest = longest\n",
    "\n",
    "        for i, (w, _) in enumerate(words):\n",
    "            self._word2ind[w] = i\n",
    "\n",
    "    def __getitem__(self, i) -> str:\n",
    "        return self._words[i]\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f'Parsed Vocabulary ({len(self._words)} words)'\n",
    "    \n",
    "    def get_words(self) -> List[str]:\n",
    "        return self._words\n",
    "    \n",
    "    def get_index(self, word) -> int:\n",
    "        if word in self._word2ind:\n",
    "            return self._word2ind[word]\n",
    "        return -1\n",
    "\n",
    "    def sen_to_seq(self, sentence: str, seq_len: int = 0, add_tokens: bool = True) -> List[int]:\n",
    "        sentence = normalize_text(sentence)\n",
    "        if seq_len <= 0:\n",
    "            seq_len = self._longest\n",
    "        l = []\n",
    "        if add_tokens:\n",
    "            sentence = f'{SOS_TOKEN} {sentence}'\n",
    "        s = sentence.split()\n",
    "        for i in range(min(len(s), seq_len - add_tokens)):\n",
    "            word = s[i]\n",
    "            if word in self._word2ind:\n",
    "                l.append(self._word2ind[word])\n",
    "            else:\n",
    "                l.append(self._word2ind[UNK_TOKEN])\n",
    "        if add_tokens:\n",
    "            l += [self._word2ind[EOS_TOKEN]]\n",
    "        if len(s) < seq_len and not add_tokens:\n",
    "            l += [self._word2ind[PAD_TOKEN]] * (seq_len - len(l))\n",
    "        return l\n",
    "\n",
    "    def conv_to_seq(self, conversation: List[Dict[str, object]], max_seq_len: int = 0) -> List[int]:\n",
    "        l = [self._word2ind[SOS_TOKEN]]\n",
    "        for conv in conversation:\n",
    "            l.extend(self.sen_to_seq(conv['line'], add_tokens=False))\n",
    "            l.append(self._word2ind[SEP_TOKEN])\n",
    "\n",
    "        if len(l) > 0:\n",
    "            l = l[:max_seq_len]\n",
    "            l[-1] = self._word2ind[EOS_TOKEN]\n",
    "        l += [self._word2ind[PAD_TOKEN]] * (max_seq_len - len(l))\n",
    "        return l\n",
    "        \n",
    "\n",
    "    def gen_mask(self, tokenized_sentence: List[int]) -> List[bool]:\n",
    "        \"\"\"Creates a mask for the given tokenized sentence.\n",
    "\n",
    "        >>> pv = ParsedVocab([('<sos>', 0), ('<eos>', 0), ('hi', 0)])\n",
    "        >>> x = pv.sen_to_seq('<sos> hi <eos> <unk> <unk>', )\n",
    "        >>> pv.gen_mask(x)\n",
    "        [1, 1, 1, 0, 0]\n",
    "        \"\"\"\n",
    "        l = [True] * len(tokenized_sentence)\n",
    "        i = len(tokenized_sentence) - 1\n",
    "        while i >= 0 and tokenized_sentence[i] == self._word2ind[PAD_TOKEN]:\n",
    "            l[i] = False\n",
    "            i -= 1\n",
    "        return l\n",
    "\n",
    "class Vocab:\n",
    "    \"\"\"Regulard vocabulary for holding the conversations and number of words.\"\"\"\n",
    "\n",
    "    DEFAULT_CONTEXT = 'default'\n",
    "\n",
    "    def __init__(self, conversation_depth: int = 4):\n",
    "        self.words = {}\n",
    "        self._context = Vocab.DEFAULT_CONTEXT\n",
    "        self.conversations = {}\n",
    "        self._held_conversations = {}\n",
    "        self.conversation_depth = conversation_depth\n",
    "        self.longest = 0\n",
    "\n",
    "    def add_word(self, word: str) -> None:\n",
    "        word = word.lower()\n",
    "        if not word in self.words:\n",
    "            self.words[word] = 0\n",
    "        self.words[word] += 1\n",
    "\n",
    "    def add_sentence(self, sentence: str) -> None:\n",
    "        sentence = f'{SOS_TOKEN} {sentence} {EOS_TOKEN}'\n",
    "        [self.add_word(s) for s in sentence.split()]\n",
    "\n",
    "    def switch_context(self, new_context: str) -> None:\n",
    "        if self._context in self._held_conversations and len(self._held_conversations[self._context]) > self.conversation_depth:\n",
    "            self.conversations[self._context].append(self._held_conversations[self._context][\n",
    "                -self.conversation_depth:\n",
    "            ])\n",
    "        self._context = new_context\n",
    "\n",
    "    def add_conversation(self, conversation: Dict[str, object]) -> None:\n",
    "        if not self._context in self.conversations:\n",
    "            self.conversations[self._context] = []\n",
    "            self._held_conversations[self._context] = [conversation]\n",
    "            return\n",
    "        self.add_line(conversation)\n",
    "        line = self._held_conversations[self._context][-1]['line'].split()\n",
    "        if len(line) > self.longest:\n",
    "            self.longest = len(line)\n",
    "    \n",
    "    def add_line(self, conversation: Dict[str, object]) -> bool:\n",
    "        if not self._context in self._held_conversations or len(self._held_conversations[self._context]) == 0:\n",
    "            self._held_conversations[self._context] = [conversation]\n",
    "            return True\n",
    "        hc = self._held_conversations[self._context] # Held Conversation\n",
    "        lc = hc[-1] # Last conversation\n",
    "        # Same speaker\n",
    "        if (len(lc['speaker']) > 0 and lc['speaker'] == conversation['speaker']) or \\\n",
    "            (len(lc['speaker']) == 0 and len(conversation['speaker']) == 0 and len(conversation['line']) > 0 and conversation['line'][0].islower()) and \\\n",
    "            conversation['when'] - lc['when'] < 1000 * 60 * 1.5:\n",
    "            hc[-1]['when'] = conversation['when']\n",
    "            hc[-1]['line'] += f\" {conversation['line']}\"\n",
    "            return False\n",
    "        if len(self._held_conversations[self._context]) >= 2:\n",
    "            self.conversations[self._context].append(self._held_conversations[self._context][\n",
    "                -min(self.conversation_depth, len(hc)):\n",
    "            ])\n",
    "        hc.append(conversation)\n",
    "        return True\n",
    "\n",
    "    def parse_vocab(self) -> ParsedVocab:\n",
    "        words = list(self.words.items())\n",
    "        return ParsedVocab(words, self.longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing folder: ditfxx_subs\n",
      "  Opening file: DitFXX (1).ass\n",
      "  Opening file: DitFXX (2).ass\n",
      "  Opening file: DitFXX (3).ass\n",
      "  Opening file: DitFXX (4).ass\n",
      "  Opening file: DitFXX (5).ass\n",
      "  Opening file: DitFXX (6).ass\n",
      "  Opening file: DitFXX (7).ass\n",
      "  Opening file: DitFXX (8).ass\n",
      "  Opening file: DitFXX (9).ass\n",
      "  Opening file: DitFXX (10).ass\n",
      "  Opening file: DitFXX (11).ass\n",
      "  Opening file: DitFXX (12).ass\n",
      "  Opening file: DitFXX (13).ass\n",
      "  Opening file: DitFXX (14).ass\n",
      "  Opening file: DitFXX (15).ass\n",
      "  Opening file: DitFXX (16).ass\n",
      "  Opening file: DitFXX (17).ass\n",
      "  Opening file: DitFXX (18).ass\n",
      "  Opening file: DitFXX (19).ass\n",
      "  Opening file: DitFXX (20).ass\n",
      "  Opening file: DitFXX (21).ass\n",
      "  Opening file: DitFXX (22).ass\n",
      "  Opening file: DitFXX (23).ass\n",
      "Parsing folder: steins_gate_subs\n",
      "  Opening file: Steins;Gate 01.ass\n",
      "  Opening file: Steins;Gate 02.ass\n",
      "  Opening file: Steins;Gate 03.ass\n",
      "  Opening file: Steins;Gate 04.ass\n",
      "  Opening file: Steins;Gate 05.ass\n",
      "  Opening file: Steins;Gate 06.ass\n",
      "  Opening file: Steins;Gate 07.ass\n",
      "  Opening file: Steins;Gate 08.ass\n",
      "  Opening file: Steins;Gate 09.ass\n",
      "  Opening file: Steins;Gate 10.ass\n",
      "  Opening file: Steins;Gate 11.ass\n",
      "  Opening file: Steins;Gate 12.ass\n",
      "  Opening file: Steins;Gate 13.ass\n",
      "  Opening file: Steins;Gate 14.ass\n",
      "  Opening file: Steins;Gate 15.ass\n",
      "  Opening file: Steins;Gate 16.ass\n",
      "  Opening file: Steins;Gate 17.ass\n",
      "  Opening file: Steins;Gate 18.ass\n",
      "  Opening file: Steins;Gate 19.ass\n",
      "  Opening file: Steins;Gate 20.ass\n",
      "  Opening file: Steins;Gate 21.ass\n",
      "  Opening file: Steins;Gate 22.ass\n",
      "  Opening file: Steins;Gate 23.ass\n",
      "  Opening file: Steins;Gate 24.ass\n",
      "  Opening file: Steins;Gate 25.ass\n",
      "Done! Num conversations: 12094, num words: 5485, longest convo: 181\n"
     ]
    }
   ],
   "source": [
    "FOLDERS = ['ditfxx_subs', 'steins_gate_subs']\n",
    "CONVERSATION_DEPTH = 4\n",
    "\n",
    "vocab = Vocab(CONVERSATION_DEPTH)\n",
    "\n",
    "for folder in FOLDERS:\n",
    "    dir = os.listdir(os.path.join('data', folder))\n",
    "    dir.sort(key=match_num)\n",
    "    print(f'Parsing folder: {folder}')\n",
    "    for f in dir:\n",
    "        filepath = os.path.join(os.getcwd(), 'data', folder, f)\n",
    "        if not os.path.isfile(filepath): continue\n",
    "        print(f'  Opening file: {f}')\n",
    "        with open(filepath, 'r', encoding='utf-8', errors='ignore') as sub_file:\n",
    "            is_event = False\n",
    "            line = True\n",
    "            while not is_event and line:\n",
    "                line = sub_file.readline()\n",
    "                if not line: break\n",
    "                if line.rstrip() == \"[Events]\":\n",
    "                    is_event = True\n",
    "            current_format = False\n",
    "            current_conversation = []\n",
    "            \n",
    "            vocab.switch_context(f)\n",
    "            line = True\n",
    "            # for line in sub_file.readlines():\n",
    "            while line:\n",
    "                try:\n",
    "                    line = sub_file.readline()\n",
    "                except UnicodeDecodeError:\n",
    "                    print('    Error decoding a line, skipped.')\n",
    "                if line.startswith('Format:'):\n",
    "                    line = line[len('Format:'):].strip().split(', ')\n",
    "                    current_format = line\n",
    "                    continue\n",
    "                if current_format == False or not line.startswith('Dialogue:'): continue\n",
    "                line = line[len('Dialogue:'):].strip().split(',')\n",
    "                line[len(current_format)-1] = ','.join(line[len(current_format)-1:])\n",
    "                dialogue = dict(zip(current_format, line))\n",
    "                if not dialogue['Style'] in ['main', 'Default']: continue\n",
    "                # Extract variables\n",
    "                speaker = dialogue['Name']\n",
    "                text = normalize_text(dialogue['Text'])\n",
    "                time = get_time(dialogue['Start'])\n",
    "\n",
    "                # if len(current_conversation) > 0 and time - current_conversation[-1]['when'] > 1000 * 60 * 2:\n",
    "                #     current_conversation = []\n",
    "                # if len(current_conversation) > 0 and ((len(speaker) > 0 and current_conversation[-1]['speaker'] == speaker) or \n",
    "                # (len(speaker) == 0 and len(dialogue['Text']) > 0 and dialogue['Text'][0].islower())):\n",
    "                #     current_conversation[-1]['line'] += f' {text}'\n",
    "                #     current_conversation[-1]['when'] = time\n",
    "                # else:\n",
    "                #     vocab.add_conversation(current_conversation)\n",
    "                #     current_conversation.append({\n",
    "                #         'speaker': speaker,\n",
    "                #         'line': text,\n",
    "                #         'when': time\n",
    "                #     })\n",
    "                # if len(current_conversation) > CONVERSATION_DEPTH:\n",
    "                #     current_conversation = current_conversation[CONVERSATION_DEPTH - len(current_conversation):]\n",
    "                # if len(current_conversation) == 1:\n",
    "                #     continue\n",
    "                vocab.add_conversation({\n",
    "                    'speaker': speaker,\n",
    "                    'line': text,\n",
    "                    'when': time\n",
    "                })\n",
    "                vocab.add_sentence(text)\n",
    "            \n",
    "\n",
    "pv = vocab.parse_vocab()\n",
    "convos = 0\n",
    "for k, c in vocab.conversations.items():\n",
    "    convos += len(c)\n",
    "print(f'Done! Num conversations: {convos}, num words: {len(pv.get_words())}, longest convo: {vocab.longest}')\n",
    "# print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'speaker': 'Z2', 'line': 'I wanna take a bath .', 'when': 150},\n",
       " {'speaker': 'Franxx',\n",
       "  'line': 'Not again . Show some self-control .',\n",
       "  'when': 2160}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(vocab.conversations)\n",
    "c = vocab.conversations[x[0]]\n",
    "c[0][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model\n",
    "Defining the actual AI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 545, 5485])\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"337pt\" height=\"752pt\"\r\n",
       " viewBox=\"0.00 0.00 336.50 752.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 748)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-748 332.5,-748 332.5,4 -4,4\"/>\r\n",
       "<!-- 2215519593232 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>2215519593232</title>\r\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"280.5,-21 184.5,-21 184.5,-0 280.5,-0 280.5,-21\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"232.5\" y=\"-7.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MeanBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519593136 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>2215519593136</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"277.5,-78 187.5,-78 187.5,-57 277.5,-57 277.5,-78\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"232.5\" y=\"-64.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">AddBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519593136&#45;&gt;2215519593232 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>2215519593136&#45;&gt;2215519593232</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M232.5,-56.9197C232.5,-49.9083 232.5,-40.1442 232.5,-31.4652\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"236,-31.3408 232.5,-21.3408 229,-31.3409 236,-31.3408\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519593376 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2215519593376</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"234,-141.5 115,-141.5 115,-120.5 234,-120.5 234,-141.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-127.9\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">UnsafeViewBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519593376&#45;&gt;2215519593136 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>2215519593376&#45;&gt;2215519593136</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M183.563,-120.391C192.279,-111.148 205.654,-96.966 216.22,-85.7628\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"218.995,-87.9213 223.31,-78.2449 213.902,-83.1186 218.995,-87.9213\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519593904 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>2215519593904</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"216,-205 133,-205 133,-184 216,-184 216,-205\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-191.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MmBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519593904&#45;&gt;2215519593376 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2215519593904&#45;&gt;2215519593376</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M174.5,-183.891C174.5,-175.366 174.5,-162.639 174.5,-151.923\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178,-151.745 174.5,-141.745 171,-151.745 178,-151.745\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519594000 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>2215519594000</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"169.5,-262 81.5,-262 81.5,-241 169.5,-241 169.5,-262\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"125.5\" y=\"-248.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">ViewBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519594000&#45;&gt;2215519593904 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>2215519594000&#45;&gt;2215519593904</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M134.035,-240.92C140.906,-233.207 150.745,-222.164 159,-212.898\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"161.694,-215.136 165.733,-205.341 156.467,-210.479 161.694,-215.136\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519594144 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>2215519594144</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"168.5,-325.5 78.5,-325.5 78.5,-304.5 168.5,-304.5 168.5,-325.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-311.9\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">SumBackward1</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519594144&#45;&gt;2215519594000 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>2215519594144&#45;&gt;2215519594000</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123.813,-304.391C124.09,-295.866 124.504,-283.139 124.852,-272.423\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"128.356,-272.353 125.183,-262.245 121.36,-272.126 128.356,-272.353\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519594240 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>2215519594240</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"168.5,-389 78.5,-389 78.5,-368 168.5,-368 168.5,-389\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-375.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">StackBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519594240&#45;&gt;2215519594144 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>2215519594240&#45;&gt;2215519594144</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123.5,-367.891C123.5,-359.366 123.5,-346.639 123.5,-335.923\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"127,-335.745 123.5,-325.745 120,-335.745 127,-335.745\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519594336 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>2215519594336</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"165.5,-446 81.5,-446 81.5,-425 165.5,-425 165.5,-446\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-432.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">SplitBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519594336&#45;&gt;2215519594240 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>2215519594336&#45;&gt;2215519594240</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M118.233,-424.92C116.855,-417.908 116.437,-408.144 116.98,-399.465\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"120.479,-399.684 118.183,-389.341 113.528,-398.858 120.479,-399.684\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519594336&#45;&gt;2215519594240 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>2215519594336&#45;&gt;2215519594240</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M128.767,-424.92C130.145,-417.908 130.563,-408.144 130.02,-399.465\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.472,-398.858 128.817,-389.341 126.521,-399.684 133.472,-398.858\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215450135248 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>2215450135248</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"201.5,-503 45.5,-503 45.5,-482 201.5,-482 201.5,-503\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-489.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">_ReversibleFunctionBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2215450135248&#45;&gt;2215519594336 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>2215450135248&#45;&gt;2215519594336</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123.5,-481.92C123.5,-474.908 123.5,-465.144 123.5,-456.465\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"127,-456.341 123.5,-446.341 120,-456.341 127,-456.341\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519594480 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>2215519594480</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"163.5,-560 83.5,-560 83.5,-539 163.5,-539 163.5,-560\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-546.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">CatBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519594480&#45;&gt;2215450135248 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>2215519594480&#45;&gt;2215450135248</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123.5,-538.92C123.5,-531.908 123.5,-522.144 123.5,-513.465\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"127,-513.341 123.5,-503.341 120,-513.341 127,-513.341\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519594576 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>2215519594576</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"168.5,-617 78.5,-617 78.5,-596 168.5,-596 168.5,-617\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"123.5\" y=\"-603.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">AddBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519594576&#45;&gt;2215519594480 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>2215519594576&#45;&gt;2215519594480</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M118.233,-595.92C116.855,-588.908 116.437,-579.144 116.98,-570.465\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"120.479,-570.684 118.183,-560.341 113.528,-569.858 120.479,-570.684\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519594576&#45;&gt;2215519594480 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>2215519594576&#45;&gt;2215519594480</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M128.767,-595.92C130.145,-588.908 130.563,-579.144 130.02,-570.465\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.472,-569.858 128.817,-560.341 126.521,-570.684 133.472,-569.858\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519594672 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>2215519594672</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"115,-674 0,-674 0,-653 115,-653 115,-674\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"57.5\" y=\"-660.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">EmbeddingBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519594672&#45;&gt;2215519594576 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>2215519594672&#45;&gt;2215519594576</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.9963,-652.92C78.6253,-644.896 92.5807,-633.266 103.96,-623.784\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"106.249,-626.431 111.691,-617.341 101.768,-621.054 106.249,-626.431\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519594816 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>2215519594816</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"107.5,-744 7.5,-744 7.5,-710 107.5,-710 107.5,-744\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"57.5\" y=\"-730.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">token_emb.weight</text>\r\n",
       "<text text-anchor=\"middle\" x=\"57.5\" y=\"-717.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (5485, 512)</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519594816&#45;&gt;2215519594672 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>2215519594816&#45;&gt;2215519594672</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.5,-709.842C57.5,-702.012 57.5,-692.54 57.5,-684.282\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"61.0001,-684.042 57.5,-674.042 54.0001,-684.042 61.0001,-684.042\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519594720 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>2215519594720</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"248,-674 133,-674 133,-653 248,-653 248,-674\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"190.5\" y=\"-660.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">EmbeddingBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519594720&#45;&gt;2215519594576 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>2215519594720&#45;&gt;2215519594576</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M178.829,-652.92C169.055,-644.896 154.888,-633.266 143.337,-623.784\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"145.438,-620.981 135.488,-617.341 140.996,-626.391 145.438,-620.981\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519594864 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>2215519594864</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"236,-744 145,-744 145,-710 236,-710 236,-744\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"190.5\" y=\"-730.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">pos_emb.weight</text>\r\n",
       "<text text-anchor=\"middle\" x=\"190.5\" y=\"-717.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (545, 512)</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519594864&#45;&gt;2215519594720 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>2215519594864&#45;&gt;2215519594720</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M190.5,-709.842C190.5,-702.012 190.5,-692.54 190.5,-684.282\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"194,-684.042 190.5,-674.042 187,-684.042 194,-684.042\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519594048 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>2215519594048</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"263,-262 192,-262 192,-241 263,-241 263,-262\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"227.5\" y=\"-248.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">TBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519594048&#45;&gt;2215519593904 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>2215519594048&#45;&gt;2215519593904</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M218.268,-240.92C210.761,-233.129 199.979,-221.94 190.995,-212.618\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"193.442,-210.113 183.983,-205.341 188.402,-214.97 193.442,-210.113\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519594192 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>2215519594192</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"274,-332 187,-332 187,-298 274,-298 274,-332\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"230.5\" y=\"-318.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">to_logits.weight</text>\r\n",
       "<text text-anchor=\"middle\" x=\"230.5\" y=\"-305.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (5485, 512)</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519594192&#45;&gt;2215519594048 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>2215519594192&#45;&gt;2215519594048</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M229.712,-297.842C229.33,-290.012 228.868,-280.54 228.465,-272.282\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"231.949,-271.859 227.965,-262.042 224.957,-272.201 231.949,-271.859\"/>\r\n",
       "</g>\r\n",
       "<!-- 2215519593808 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>2215519593808</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"328.5,-148 252.5,-148 252.5,-114 328.5,-114 328.5,-148\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"290.5\" y=\"-134.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">to_logits.bias</text>\r\n",
       "<text text-anchor=\"middle\" x=\"290.5\" y=\"-121.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (5485)</text>\r\n",
       "</g>\r\n",
       "<!-- 2215519593808&#45;&gt;2215519593136 -->\r\n",
       "<g id=\"edge19\" class=\"edge\"><title>2215519593808&#45;&gt;2215519593136</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M275.261,-113.842C267.038,-105.122 256.894,-94.3655 248.549,-85.5176\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"250.906,-82.9156 241.499,-78.0419 245.814,-87.7183 250.906,-82.9156\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x203d74221c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from performer_pytorch import PerformerLM\n",
    "\n",
    "# 3 Sentences with 2 delims\n",
    "seq_len = vocab.longest * (vocab.conversation_depth - 1) + 2\n",
    "\n",
    "# Thanks to\n",
    "# https://github.com/lucidrains/performer-pytorch\n",
    "model = PerformerLM(\n",
    "    num_tokens=len(pv.get_words()),\n",
    "    max_seq_len=seq_len,\n",
    "    dim=512,\n",
    "    depth=6,\n",
    "    heads=16,\n",
    "    causal=False,\n",
    "    nb_features=256,\n",
    "    generalized_attention=False,\n",
    "    kernel_fn=nn.ReLU(),\n",
    "    reversible=True,\n",
    "    ff_chunks=10,\n",
    "    use_scalenorm=False,\n",
    "    use_rezero=True\n",
    ")\n",
    "\n",
    "x = torch.randint(0, len(pv.get_words()), (1, seq_len))\n",
    "mask = torch.ones_like(x).bool()\n",
    "\n",
    "y = model(x, mask=mask)\n",
    "\n",
    "print(y.size())\n",
    "\n",
    "make_dot(y.mean(), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adafactor(model.parameters())\n",
    "\n",
    "class ConversationIter:\n",
    "\n",
    "    def __init__(self, vocab: Vocab, parsed_vocab: ParsedVocab, max_seq_len: int):\n",
    "        self._vocab = vocab\n",
    "        self._parsed_vocab = parsed_vocab\n",
    "        self._context = random.choice(list(vocab.conversations))\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        self._i = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._context = random.choice(list(self._vocab.conversations))\n",
    "        self._i = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._i >= len(self._vocab.conversations[self._context]):\n",
    "            raise StopIteration\n",
    "        x = self._vocab.conversations[self._context][self._i]\n",
    "        input = torch.tensor(self._parsed_vocab.conv_to_seq(x[:-1], self.max_seq_len))\n",
    "        target = torch.tensor(self._parsed_vocab.sen_to_seq(x[-1]['line']))\n",
    "        self._i += 1\n",
    "        return input, target\n",
    "\n",
    "def train(conv_iter: ConversationIter):\n",
    "    model.train()\n",
    "    for input, target in conv_iter:\n",
    "        input.to(device)\n",
    "        target.to(device)\n",
    "\n",
    "        mask = torch.tensor(pv.gen_mask(input))\n",
    "\n",
    "        # input.unsqueeze_(0)\n",
    "        # target.unsqueeze_(0)\n",
    "        # mask.unsqueeze_(0)\n",
    "\n",
    "        input = F.one_hot(input, len(pv.get_words()))\n",
    "        input.transpose_(0, 1)\n",
    "\n",
    "        print(input.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input, mask=mask)\n",
    "        loss = F.cross_entropy(output.view(-1, len(pv.get_words())), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5485, 545])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4673c61dd660>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAIN_ITERS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mPRINT_EVERY\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Iter: {iter+1}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-00e339c12f93>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(conv_iter)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_emb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPerformerLM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\reversible.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'f_args'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'g_args'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0m_ReversibleFunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\reversible.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, x, blocks, args)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\reversible.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, f_args, g_args)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mf_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mg_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\reversible.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, record_rng, set_rng, *args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mset_rng\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mrng_devices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPreScaleNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\performer_pytorch\\performer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m             \u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_fill_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "TRAIN_ITERS = 3\n",
    "PRINT_EVERY = 1\n",
    "\n",
    "conv_iter = ConversationIter(vocab, pv, seq_len)\n",
    "\n",
    "for iter in range(TRAIN_ITERS):\n",
    "    train(conv_iter)\n",
    "    if iter + 1 % PRINT_EVERY == 0:\n",
    "        print(f'Iter: {iter+1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
